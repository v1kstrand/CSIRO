{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0900041",
   "metadata": {},
   "source": [
    "# CSIRO Biomass (Kaggle) — Baseline + Ablations\n",
    "\n",
    "## Baseline\n",
    "\n",
    "### Data & evaluation\n",
    "\n",
    "* **Tiny data (~357 unique train images)** → overfit risk is the main constraint.\n",
    "* **Train table is long-format:** ~1785 rows = 357 images × 5 targets → pivot to **wide (357 rows)** for training.\n",
    "* **Validation:** grouped CV by the true sampling unit (no row-level splits).\n",
    "\n",
    "  * candidate splits to try (ablation):\n",
    "\n",
    "    * **Group by `Sampling_Date`** (often improves CV↔LB realism)\n",
    "    * stratify by **State** (target distributions differ by state)\n",
    "* **Submission/inference:** images only (treat metadata as train-only).\n",
    "\n",
    "### Model\n",
    "\n",
    "* **Backbone:** DINOv3 (**frozen**)\n",
    "* **Neck:** none (baseline)\n",
    "\n",
    "### Head\n",
    "\n",
    "* **2-layer MLP** → **5 outputs** (`Green, Clover, Dead, GDM, Total`)\n",
    "* Use LayerNorm (or keep backbone norm), dropout ~0.1–0.3.\n",
    "\n",
    "### Targets & loss\n",
    "\n",
    "* Train on **log1p** targets.\n",
    "* Baseline loss: **weighted MSE** in log-space.\n",
    "\n",
    "  * weights roughly: `Green=0.1, Clover=0.1, Dead=0.1, GDM=0.2, Total=0.5`\n",
    "* Metric: global weighted R² (in original space) computed across all targets.\n",
    "\n",
    "### Augmentation (label-safe)\n",
    "\n",
    "Goal: improve robustness without breaking the “grams ↔ pixels” relationship.\n",
    "\n",
    "* Safe geometric:\n",
    "\n",
    "  * flips\n",
    "  * 90° rotations\n",
    "  * small translate/shear (no scale)\n",
    "  * **jigsaw (patch shuffle):** split into a small grid (e.g., 3×3) and randomly permute patches (use low probability; preserves scale but breaks global layout)\n",
    "* Photometric:\n",
    "\n",
    "  * brightness/contrast/saturation/hue jitter\n",
    "  * mild blur\n",
    "  * mild autocontrast\n",
    "    Avoid:\n",
    "* random resized crop / heavy zoom\n",
    "* cutout / random erasing\n",
    "* heavy rotations that require re-scaling\n",
    "\n",
    "### Training hygiene\n",
    "\n",
    "* Use AMP (BF16).\n",
    "* Consider cosine LR + warmup.\n",
    "* Consider EMA/SWA once baseline is stable.\n",
    "* Clip gradients (e.g., 1.0 norm) if training is noisy.\n",
    "\n",
    "## Ablations\n",
    "\n",
    "### A) Must-verify (rules + correctness)\n",
    "\n",
    "* Verify that each image has all 5 targets after pivot (wide).\n",
    "* Verify metric implementation matches the competition definition.\n",
    "* Verify no leakage: same `Sampling_Date` never appears in both train and val.\n",
    "\n",
    "### B) Baseline implementation decisions\n",
    "\n",
    "* Compare CV split strategies:\n",
    "\n",
    "  * GroupKFold by `Sampling_Date`\n",
    "  * StratifiedGroupKFold by `State` with groups=`Sampling_Date`\n",
    "* Compare head sizes / dropout.\n",
    "\n",
    "### C) CV evaluation protocol\n",
    "\n",
    "* Report mean ± std across folds.\n",
    "* Track per-target metrics for diagnostics.\n",
    "* Keep the split fixed across experiments.\n",
    "\n",
    "### D) Inference stability\n",
    "\n",
    "* Test-time augmentation (TTA): rotations/flips.\n",
    "* Average predictions in log-space vs original space.\n",
    "\n",
    "$1$2- Try **jigsaw (patch shuffle)**: 3×3 or 4×4 grid, low probability, validate under CV.\n",
    "\n",
    "$3 Tiling (multi-crop / multi-instance)\n",
    "\n",
    "* **Tiled backbone features:** split each image into an `n×n` grid (start with **2×2**) and run the frozen DINO backbone on each tile.\n",
    "* **Pooling (keep it simple):**\n",
    "\n",
    "  * mean pool tile embeddings → single feature → head\n",
    "  * (optional) mean+max concat (still simple)\n",
    "  * (optional) per-tile head then mean of predictions\n",
    "* **If images are stitched left/right:** tile each half separately → pool L and R → concat `[L, R]` → head.\n",
    "* **Ablate:** `n=1` (no tiling) vs `n=2` vs `n=3` (compute-heavy) and pooling choice.\n",
    "\n",
    "### G) Improvements (after baseline is stable)\n",
    "\n",
    "* Unfreeze last N blocks (careful with overfit).\n",
    "* SWA/EMA.\n",
    "* Better heads (depth/width).\n",
    "* Regularization sweeps.\n",
    "\n",
    "## Insights\n",
    "\n",
    "* Host: public/private split is **not fully random**; test includes some **non-overlapping** time/location periods.\n",
    "* Group by `Sampling_Date` to reduce leakage from date-correlated collection conditions.\n",
    "* With ~300 images, CV is noisy; report mean±std and avoid “seed shopping”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219733c8",
   "metadata": {},
   "source": [
    "**Repo note:** core code is also packaged under `src/csiro_biomass/` (see `scripts/train_cv.py`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb2168e",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca52cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pathlib, yaml\n",
    "yaml_path = \"/notebooks/env.yaml\"\n",
    "\n",
    "with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "    env = yaml.safe_load(f)\n",
    "\n",
    "for k, v in env.items():\n",
    "    os.environ[k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967469fd",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3caad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WB = \"https://dinov3.llamameta.net/dinov3_vitb16/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "WL = \"https://dinov3.llamameta.net/dinov3_vitl16/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "WL_plus = \"https://dinov3.llamameta.net/dinov3_vith16plus/dinov3_vith16plus_pretrain_lvd1689m-7c1da9a5.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbbdf3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "WB = \"https://dinov3.llamameta.net/dinov3_vitb16/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "WL = \"https://dinov3.llamameta.net/dinov3_vitl16/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "WL_plus = \"https://dinov3.llamameta.net/dinov3_vith16plus/dinov3_vith16plus_pretrain_lvd1689m-7c1da9a5.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from itertools import chain\n",
    "\n",
    "\"\"\"os.environ[\"TORCHINDUCTOR_FX_GRAPH_CACHE\"]=\"1\"\n",
    "os.environ[\"TORCHINDUCTOR_AUTOGRAD_CACHE\"]=\"1\"\n",
    "os.environ[\"TORCHINDUCTOR_CACHE_DIR\"] = \"/notebooks/dinov3/compile_cache\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import comet_ml\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"/notebooks/dinov3\")  # your fork\n",
    "from dinov3.layers.block import SelfAttentionBlock\n",
    "\n",
    "\"\"\"torch.backends.cuda.enable_flash_sdp(True)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(False)\n",
    "\n",
    "dynamo_config = torch._dynamo.config\n",
    "dynamo_config.compiled_autograd = True\n",
    "dynamo_config.capture_scalar_outputs = False\n",
    "dynamo_config.cache_size_limit = 512\"\"\"\n",
    "\n",
    "#torch.set_float32_matmul_precision(\"highest\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# data: long -> wide\n",
    "# -------------------------\n",
    "def load_train_wide(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    idx_cols = [\"image_path\", \"Sampling_Date\", \"State\", \"Species\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\"]\n",
    "    wide = (\n",
    "        df.pivot_table(index=idx_cols, columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "          .reset_index()\n",
    "    )\n",
    "    for t in TARGETS:\n",
    "        if t not in wide.columns:\n",
    "            wide[t] = np.nan\n",
    "    wide = wide.dropna(subset=TARGETS).reset_index(drop=True)\n",
    "    wide[\"abs_path\"] = wide[\"image_path\"].apply(lambda p: os.path.join(ROOT, p))\n",
    "    return wide\n",
    "\n",
    "model_size = \"b\"\n",
    "W = WB\n",
    "plus = \"\"\n",
    "COMPILE_MODEL = False\n",
    "REPO_DIR = \"/notebooks/dinov3\"\n",
    "DINO_WEIGHTS = f\"/notebooks/dinov3/weights/dinov3_vit{model_size}16_pretrain{plus}.pth\"\n",
    "MODEL = torch.hub.load(REPO_DIR, f'dinov3_vit{model_size}16{plus.replace(\"_\", \"\")}', source='local', weights=DINO_WEIGHTS, verbose=True)\n",
    "#MODEL_PLUS = torch.hub.load(REPO_DIR, f'dinov3_vit{model_size}16plus', source='local', weights=WL_plus, verbose=True)\n",
    "NUM_WORKERS = os.cpu_count() - 2\n",
    "ROOT = \"/notebooks/kaggle/csiro\"\n",
    "CSV_PATH = os.path.join(ROOT, \"train.csv\")\n",
    "TARGETS = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "WIDE_DF=load_train_wide(CSV_PATH)\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "IMG_SIZE = 512\n",
    "SEED = 420\n",
    "DTYPE = torch.bfloat16  # set to torch.bfloat16 on GPUs that support it\n",
    "RUN_SWEEPS = True  # set True to run CV sweeps\n",
    "FEAT_DIM = MODEL.norm.normalized_shape[0]\n",
    "NUM_HEADS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2d1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, out_path: str, chunk_size: int = 1024 * 1024):\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    with requests.get(url, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:  # filter keep-alive chunks\n",
    "                    f.write(chunk)\n",
    "    return out_path\n",
    "\n",
    "# example\n",
    "url = \"https://dinov3.llamameta.net/dinov3_vitl16/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "out_path = \"/notebooks/dinov3/weights/dinov3_vitl16_pretrain.pth\"\n",
    "#download_file(url, out_path)\n",
    "#print(\"Saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b93b45",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5eb40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _denorm_img(x: torch.Tensor, mean=IMAGENET_MEAN, std=IMAGENET_STD) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: [3,H,W] float tensor normalized with mean/std.\n",
    "    returns: [3,H,W] in [0,1]\n",
    "    \"\"\"\n",
    "    mean = torch.tensor(mean, dtype=x.dtype, device=x.device).view(3, 1, 1)\n",
    "    std  = torch.tensor(std,  dtype=x.dtype, device=x.device).view(3, 1, 1)\n",
    "    x = x * std + mean\n",
    "    return x.clamp(0, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def show_nxn_grid(dataset=None, dataloader=None, n=4, indices=None, seed=0,\n",
    "                  mean=IMAGENET_MEAN, std=IMAGENET_STD,\n",
    "                  show_targets=True, targets_are_log1p=True, figsize_per_cell=3.0):\n",
    "    assert (dataset is not None) ^ (dataloader is not None), \"Pass exactly one of dataset or dataloader.\"\n",
    "    k = n * n\n",
    "    xs, ys = [], []\n",
    "    if dataset is not None:\n",
    "        if indices is None:\n",
    "            rng = random.Random(seed)\n",
    "            indices = [rng.randrange(len(dataset)) for _ in range(k)]\n",
    "        else:\n",
    "            assert len(indices) >= k, f\"Need at least {k} indices.\"\n",
    "\n",
    "        for i in indices[:k]:\n",
    "            x, y = dataset[i]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "        x_batch = torch.stack(xs, dim=0)  # [k,3,H,W]\n",
    "        y_batch = torch.stack(ys, dim=0) if show_targets else None\n",
    "\n",
    "    else:\n",
    "        for xb, yb in dataloader:\n",
    "            for j in range(xb.shape[0]):\n",
    "                xs.append(xb[j])\n",
    "                ys.append(yb[j])\n",
    "                if len(xs) >= k:\n",
    "                    break\n",
    "            if len(xs) >= k:\n",
    "                break\n",
    "\n",
    "        x_batch = torch.stack(xs, dim=0)\n",
    "        y_batch = torch.stack(ys, dim=0) if show_targets else None\n",
    "\n",
    "    # plot\n",
    "    fig, axes = plt.subplots(n, n, figsize=(n * figsize_per_cell, n * figsize_per_cell))\n",
    "    axes = np.asarray(axes)\n",
    "\n",
    "    for idx in range(k):\n",
    "        ax = axes[idx // n, idx % n]\n",
    "        x = _denorm_img(x_batch[idx], mean=mean, std=std)\n",
    "        img = x.permute(1, 2, 0).cpu().numpy()  # [H,W,3] in [0,1]\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        if show_targets and (y_batch is not None):\n",
    "            y = y_batch[idx].detach().cpu()\n",
    "            if targets_are_log1p:\n",
    "                y = torch.expm1(y).clamp_min(0.0)\n",
    "            # short title\n",
    "            ax.set_title(\" \".join([f\"{v:.2f}\" for v in y.tolist()]), fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class TileEncoder(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module, input_res: int):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.input_res = input_res\n",
    "\n",
    "    def forward(self, x: torch.Tensor, grid):\n",
    "        B, C, H, W = x.shape\n",
    "        r, c = grid\n",
    "        hs = torch.linspace(0, H, steps=r + 1, device=x.device).round().long()\n",
    "        ws = torch.linspace(0, W, steps=c + 1, device=x.device).round().long()\n",
    "        tiles = []\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                rs, re = hs[i].item(), hs[i + 1].item()\n",
    "                cs, ce = ws[j].item(), ws[j + 1].item()\n",
    "                xt = x[:, :, rs:re, cs:ce]\n",
    "                if xt.shape[-2:] != (self.input_res, self.input_res):\n",
    "                    xt = F.interpolate(xt, size=(self.input_res, self.input_res), mode=\"bilinear\", align_corners=False)\n",
    "                tiles.append(xt)\n",
    "        tiles = torch.stack(tiles, dim=1)\n",
    "        flat = tiles.view(-1, C, self.input_res, self.input_res)\n",
    "        feats = self.backbone(flat)\n",
    "        feats = feats.view(B, -1, feats.shape[-1])\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36b7ff",
   "metadata": {},
   "source": [
    "# Train Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc093015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# transforms\n",
    "# -------------------------\n",
    "class PadToSquare:\n",
    "    def __init__(self, fill=0):\n",
    "        self.fill = fill\n",
    "\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        w, h = img.size\n",
    "        if w == h:\n",
    "            return img\n",
    "        s = max(w, h)\n",
    "        new = Image.new(img.mode, (s, s), color=self.fill)\n",
    "        new.paste(img, ((s - w) // 2, (s - h) // 2))\n",
    "        return new\n",
    "\n",
    "def get_tfms():\n",
    "    return T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomChoice([\n",
    "            T.Lambda(lambda x: x),\n",
    "            T.RandomRotation((90, 90)),\n",
    "            T.RandomRotation((180, 180)),\n",
    "            T.RandomRotation((270, 270)),\n",
    "        ]),\n",
    "        T.ColorJitter(brightness=0.20, contrast=0.20, saturation=0.20, hue=0.04),\n",
    "\n",
    "    ])\n",
    "\n",
    "def post_tfms(): \n",
    "    normalize = T.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                            std=(0.229, 0.224, 0.225))\n",
    "\n",
    "    return T.Compose([T.ToTensor(),normalize])\n",
    "# -------------------------\n",
    "# dataset\n",
    "# -------------------------\n",
    "\n",
    "class BiomassBaseCached(Dataset):\n",
    "    \"\"\"Caches resized/padded PIL images + stores y_log once.\"\"\"\n",
    "    def __init__(self, wide_df, img_size=IMG_SIZE):\n",
    "        self.df = wide_df.reset_index(drop=True)\n",
    "        y = self.df[TARGETS].values.astype(np.float32)\n",
    "        self.y_log = np.log1p(y)\n",
    "\n",
    "        # cache at fixed size (PIL)\n",
    "        pre = T.Compose([\n",
    "            PadToSquare(fill=0),\n",
    "            T.Resize((img_size, img_size), antialias=True),\n",
    "        ])\n",
    "        self.imgs = []\n",
    "        for p in self.df[\"abs_path\"].tolist():\n",
    "            im = Image.open(p).convert(\"RGB\")\n",
    "            im = pre(im)\n",
    "            self.imgs.append(im.copy())\n",
    "            im.close()\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.imgs[i], torch.from_numpy(self.y_log[i])  # PIL, y_log\n",
    "\n",
    "\n",
    "class TransformView(Dataset):\n",
    "    \"\"\"Applies train/val transforms on top of the same cached base dataset.\"\"\"\n",
    "    def __init__(self, base: BiomassBaseCached, tfms):\n",
    "        self.base = base\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __len__(self): return len(self.base)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img, y = self.base[i]          # img is cached PIL\n",
    "        x = self.tfms(img)             # apply aug+tensor+norm OR tensor+norm\n",
    "        return x, y\n",
    "\n",
    "    \n",
    "# -------------------------\n",
    "# Loss\n",
    "# -------------------------  \n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, weights=(0.1, 0.1, 0.1, 0.2, 0.5), normalize=True):\n",
    "        super().__init__()\n",
    "        w = torch.as_tensor(weights, dtype=torch.float32)\n",
    "        self.register_buffer(\"w\", w)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, pred_log: torch.Tensor, target_log: torch.Tensor) -> torch.Tensor:\n",
    "        w = self.w.view(1, -1)\n",
    "        err2 = (pred_log - target_log).pow(2)\n",
    "        loss = (err2 * w).sum(dim=-1)\n",
    "        if self.normalize:\n",
    "            loss = loss / (self.w.sum() + 1e-12)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# model: frozen DINOv3 + head\n",
    "# -------------------------\n",
    "class DINOv3Regressor(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module, hidden=1024, depth=2, drop=0.1, out_dim=5, feat_dim = None, norm=None, num_neck=1):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        feat_dim = feat_dim or FEAT_DIM\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        self.backbone.eval()\n",
    "\n",
    "        assert not num_neck or feat_dim == 768, \"Only VIT B is supported for now for neck\"\n",
    "        neck = []\n",
    "        for _ in range(num_neck):\n",
    "            neck.append(SelfAttentionBlock(feat_dim, num_heads=12))\n",
    "        self.neck = nn.Sequential(*neck) if neck else []\n",
    "\n",
    "        if depth < 2:\n",
    "            raise ValueError(f\"depth must be >= 2 (got {depth})\")\n",
    "        \n",
    "        layers = []\n",
    "        in_dim = feat_dim\n",
    "        norm_layer = norm or nn.LayerNorm\n",
    "        for _ in range(depth - 1):\n",
    "            layers += [nn.Linear(in_dim, hidden), norm_layer(hidden), nn.GELU(), nn.Dropout(drop)]\n",
    "            in_dim = hidden\n",
    "        layers += [nn.Linear(in_dim, out_dim)]\n",
    "        self.head = nn.Sequential(*layers)\n",
    "        self.norm = norm_layer(feat_dim)\n",
    "        self.init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x, rope = self.backbone(x)\n",
    "            x = x[\"x_prenorm\"]\n",
    "            \n",
    "        for neck in self.neck:\n",
    "            x = neck(x, rope)\n",
    "        x = self.norm(x[: , 0, :])\n",
    "        return self.head(x)  \n",
    "    \n",
    "    def set_train(self, train = True):\n",
    "        self.neck.train(train)\n",
    "        self.head.train(train)\n",
    "        self.norm.train(train)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def init(self):\n",
    "        modules = [*self.head.modules(), *self.neck.modules(), *self.norm.modules()]\n",
    "        for m in modules:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                if m.elementwise_affine:\n",
    "                    nn.init.ones_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d27c93",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b61e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_global_wr2(model, dl_va, w_vec, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    w5 = w_vec.to(device).view(1, -1)\n",
    "    ss_res  = torch.zeros((), device=device)\n",
    "    sum_w   = torch.zeros((), device=device)\n",
    "    sum_wy  = torch.zeros((), device=device)\n",
    "    sum_wy2 = torch.zeros((), device=device)\n",
    "\n",
    "    with torch.inference_mode(), torch.amp.autocast(device_type=\"cuda\", dtype=DTYPE, enabled=device.startswith(\"cuda\")):\n",
    "        for x, y_log in dl_va:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y_log = y_log.to(device, non_blocking=True)   # log1p targets\n",
    "            p_log = model(x).float()                      # log1p preds\n",
    "\n",
    "            y = torch.expm1(y_log)\n",
    "            p = torch.expm1(p_log).clamp_min(0.0)\n",
    "\n",
    "            w = w5.expand_as(y)                           # [B, 5]\n",
    "            diff = (y - p)\n",
    "\n",
    "            ss_res  += (w * diff * diff).sum()\n",
    "            sum_w   += w.sum()\n",
    "            sum_wy  += (w * y).sum()\n",
    "            sum_wy2 += (w * y * y).sum()\n",
    "\n",
    "    mu = sum_wy / (sum_w + 1e-12)\n",
    "    ss_tot = sum_wy2 - sum_w * mu * mu\n",
    "    score = (1.0 - ss_res / (ss_tot + 1e-12)).item()\n",
    "    return score\n",
    "\n",
    "def cos_sin_lr(ep: int, epochs: int, lr_start: float, lr_final: float) -> float:\n",
    "    if epochs <= 1:\n",
    "        return lr_final\n",
    "    t = (ep - 1) / (epochs - 1)  # 0 -> 1\n",
    "    return lr_final + 0.5 * (lr_start - lr_final) * (1.0 + math.cos(math.pi * t))\n",
    "\n",
    "def set_optimizer_lr(opt, lr: float):\n",
    "    for pg in opt.param_groups:\n",
    "        pg[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f7f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(\n",
    "    ds_tr_view,\n",
    "    ds_va_view,\n",
    "    backbone,\n",
    "    tr_idx,\n",
    "    va_idx,\n",
    "    wd=1e-4,\n",
    "    fold_idx=0,\n",
    "    epochs=5,\n",
    "    lr_start=3e-4,\n",
    "    lr_final=5e-5,\n",
    "    batch_size=128,\n",
    "    clip_val=3,\n",
    "    device=\"cuda\",\n",
    "    save_path=None,\n",
    "    verbose=False,\n",
    "    plot_imgs=False,\n",
    "    early_stopping=6,\n",
    "    head_hidden=1024,\n",
    "    head_depth=2,\n",
    "    head_drop=0.1,\n",
    "    num_neck=0,\n",
    "    comet_exp=None,\n",
    "    skip_log_first_n=5,\n",
    "    curr_fold=0,\n",
    "\n",
    "    # --- SWA phase ---\n",
    "    swa_epochs=15,\n",
    "    swa_lr=None,\n",
    "    swa_anneal_epochs=10,\n",
    "    swa_load_best=True,\n",
    "    swa_eval_freq=2,\n",
    "):\n",
    "\n",
    "    def _trainable_blocks(m: nn.Module):\n",
    "        parts = []\n",
    "        if hasattr(m, \"neck\") and m.neck is not None:\n",
    "            parts.append(m.neck)\n",
    "        if hasattr(m, \"head\") and m.head is not None:\n",
    "            parts.append(m.head)\n",
    "        if hasattr(m, \"norm\") and m.norm is not None:\n",
    "            parts.append(m.norm)\n",
    "        return parts\n",
    "\n",
    "    def _trainable_params_list(m: nn.Module):\n",
    "        blocks = _trainable_blocks(m)\n",
    "        params = list(chain.from_iterable(b.parameters() for b in blocks))\n",
    "        params = [p for p in params if p.requires_grad]\n",
    "        return params\n",
    "\n",
    "    def _save_parts(m):\n",
    "        state = {}\n",
    "        for name in (\"neck\", \"head\", \"norm\"):\n",
    "            part = getattr(m, name, None)\n",
    "            if part is not None:\n",
    "                state[name] = {k: v.detach().cpu() for k, v in part.state_dict().items()}\n",
    "        return state\n",
    "\n",
    "    def _load_parts(m, state):\n",
    "        for name in (\"neck\", \"head\", \"norm\"):\n",
    "            part = getattr(m, name, None)\n",
    "            if part is not None and name in state:\n",
    "                part.load_state_dict(state[name], strict=True)\n",
    "\n",
    "    # ---- data ----\n",
    "    tr_subset = Subset(ds_tr_view, tr_idx)\n",
    "    va_subset = Subset(ds_va_view, va_idx)\n",
    "\n",
    "    dl_kwargs = dict(\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        persistent_workers=(NUM_WORKERS > 0),\n",
    "    )\n",
    "    dl_tr = DataLoader(tr_subset, shuffle=True, **dl_kwargs)\n",
    "    dl_va = DataLoader(va_subset, shuffle=False, **dl_kwargs)\n",
    "\n",
    "    if plot_imgs:\n",
    "        show_nxn_grid(dataloader=dl_tr, n=4)\n",
    "        return\n",
    "\n",
    "    # ---- model ----\n",
    "    model = DINOv3Regressor(\n",
    "        backbone, hidden=head_hidden, drop=head_drop, depth=head_depth, num_neck=num_neck\n",
    "    ).to(device)\n",
    "    model.init()\n",
    "\n",
    "    criterion = WeightedMSELoss().to(device)\n",
    "\n",
    "    trainable_params = _trainable_params_list(model)\n",
    "    opt = torch.optim.AdamW(trainable_params, lr=lr_start, weight_decay=wd)\n",
    "\n",
    "    scaler = None\n",
    "    if device.startswith(\"cuda\") and DTYPE == torch.float16:\n",
    "        scaler = torch.amp.GradScaler()\n",
    "\n",
    "    if swa_lr is None:\n",
    "        swa_lr = lr_final\n",
    "\n",
    "    # ---- bookkeeping ----\n",
    "    best_score = -1e9\n",
    "    best_state = None\n",
    "    best_opt_state = None\n",
    "    patience = 0\n",
    "\n",
    "    # =========================\n",
    "    # Phase A: normal training\n",
    "    # =========================\n",
    "    p_bar = tqdm(range(1, epochs + 1))\n",
    "    for ep in p_bar:\n",
    "        lr = cos_sin_lr(ep, epochs, lr_start, lr_final)\n",
    "        set_optimizer_lr(opt, lr)\n",
    "\n",
    "        model.set_train(True)\n",
    "        running = 0.0\n",
    "        n_seen = 0\n",
    "\n",
    "        for x, y_log in dl_tr:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y_log = y_log.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=DTYPE, enabled=device.startswith(\"cuda\")):\n",
    "                p_log = model(x)\n",
    "                loss = criterion(p_log, y_log)\n",
    "\n",
    "            if scaler is not None:\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # unscale before clipping\n",
    "                if clip_val and clip_val > 0:\n",
    "                    scaler.unscale_(opt)\n",
    "                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=float(clip_val))\n",
    "\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "                if clip_val and clip_val > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=float(clip_val))\n",
    "\n",
    "                opt.step()\n",
    "\n",
    "            bs = x.size(0)\n",
    "            running += loss.detach() * bs\n",
    "            n_seen += bs\n",
    "\n",
    "        train_loss = (running / max(n_seen, 1)).item()\n",
    "        model.set_train(False)\n",
    "        score = eval_global_wr2(model, dl_va, criterion.w, device=device)\n",
    "\n",
    "        if comet_exp is not None and ep > skip_log_first_n:\n",
    "            comet_exp.log_metrics(\n",
    "                {f\"train_loss_{curr_fold}\": train_loss, f\"val_wR2_{curr_fold}\": score},\n",
    "                step=ep,\n",
    "            )\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            patience = 0\n",
    "            best_state = _save_parts(model)\n",
    "            best_opt_state = copy.deepcopy(opt.state_dict())\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        s1 = f\"Best score: {best_score:.4f} | Patience: {patience:02d}/{early_stopping:02d} | lr: {lr:6.4f}\"\n",
    "        s2 = f\"[fold {fold_idx}] | train_loss={train_loss:.4f} | val_wR2={score:.4f} | {s1}\"\n",
    "        if verbose:\n",
    "            print(s2)\n",
    "        p_bar.set_postfix_str(s2)\n",
    "\n",
    "        if patience >= early_stopping:\n",
    "            p_bar.set_postfix_str(s2 + \" | Early stopping -> SWA phase\")\n",
    "            break\n",
    "\n",
    "    p_bar.close()\n",
    "\n",
    "    if (swa_epochs <= 0) or (best_state is None):\n",
    "        if save_path and best_state is not None:\n",
    "            torch.save(best_state, save_path)\n",
    "        return best_score\n",
    "\n",
    "    # =========================\n",
    "    # Phase B: SWA extra epochs\n",
    "    # =========================\n",
    "    if swa_load_best:\n",
    "        _load_parts(model, best_state)\n",
    "        if best_opt_state is not None:\n",
    "            opt.load_state_dict(best_opt_state)\n",
    "\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_sched = SWALR(opt, swa_lr=swa_lr, anneal_epochs=swa_anneal_epochs, anneal_strategy=\"cos\")\n",
    "\n",
    "    p_bar = tqdm(range(1, swa_epochs + 1))\n",
    "    swa_score = None\n",
    "\n",
    "    for k in p_bar:\n",
    "        model.set_train(True)\n",
    "        running = 0.0\n",
    "        swa_n_seen = 0\n",
    "\n",
    "        for x, y_log in dl_tr:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y_log = y_log.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=DTYPE, enabled=device.startswith(\"cuda\")):\n",
    "                p_log = model(x)\n",
    "                loss = criterion(p_log, y_log)\n",
    "\n",
    "            if scaler is not None:\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if clip_val and clip_val > 0:\n",
    "                    scaler.unscale_(opt)\n",
    "                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=float(clip_val))\n",
    "\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "                if clip_val and clip_val > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=float(clip_val))\n",
    "\n",
    "                opt.step()\n",
    "\n",
    "            bs = x.size(0)\n",
    "            running += loss.detach() * bs\n",
    "            swa_n_seen += bs\n",
    "\n",
    "        swa_loss = (running / max(swa_n_seen, 1)).item()\n",
    "\n",
    "        swa_sched.step()\n",
    "        swa_model.update_parameters(model)\n",
    "\n",
    "        if comet_exp is not None:\n",
    "            comet_exp.log_metrics({f\"swa_train_loss_{curr_fold}\": swa_loss}, step=k)\n",
    "\n",
    "        s2 = f\"[fold {fold_idx}] | swa_loss={swa_loss:.4f}\"\n",
    "        if verbose:\n",
    "            print(s2)\n",
    "        p_bar.set_postfix_str(s2)\n",
    "\n",
    "        if swa_eval_freq and (k % swa_eval_freq == 0):\n",
    "            swa_score = eval_global_wr2(swa_model, dl_va, criterion.w, device=device)\n",
    "            if comet_exp is not None:\n",
    "                comet_exp.log_metrics({f\"swa_wR2_{curr_fold}\": swa_score}, step=k)\n",
    "\n",
    "    p_bar.close()\n",
    "\n",
    "    if swa_score is None or (swa_eval_freq and (k % swa_eval_freq) != 0):\n",
    "        swa_score = eval_global_wr2(swa_model, dl_va, criterion.w, device=device)\n",
    "\n",
    "    if save_path:\n",
    "        swa_blocks_state = _save_parts(swa_model.module)\n",
    "        torch.save(swa_blocks_state, save_path)\n",
    "\n",
    "    return swa_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94945377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_groupkfold_cv(\n",
    "    dataset,\n",
    "    wide_df,\n",
    "    n_splits=5,\n",
    "    group_col=\"Sampling_Date\",\n",
    "    tfms_fn = get_tfms,\n",
    "    comet_exp_name = None,\n",
    "    sweep_config = \"\",\n",
    "    **train_kwargs,\n",
    "):\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    X = wide_df  \n",
    "    y = wide_df[\"State\"].values             \n",
    "    groups = wide_df[group_col].values\n",
    "    ds_tr_view = TransformView(dataset, T.Compose([tfms_fn(), post_tfms()]))\n",
    "    ds_va_view = TransformView(dataset, post_tfms())\n",
    "    \n",
    "    \"\"\"\n",
    "    bb_copy = copy.deepcopy(backbone)\n",
    "    model = DINOv3Regressor(bb_copy, hidden=head_hidden, drop=head_drop, depth=head_depth, norm=head_norm).to(device)\n",
    "    \n",
    "    if COMPILE_MODEL:\n",
    "        model.compile(fullgraph=True, mode=\"default\", backend=\"inductor\", dynamic=True)\n",
    "    \"\"\"\n",
    "    if comet_exp_name is not None:\n",
    "        comet_exp = comet_ml.start(\n",
    "            api_key=os.getenv(\"COMET_API_KEY\"),\n",
    "            project_name=comet_exp_name,\n",
    "            experiment_key=None\n",
    "        )\n",
    "    fold_scores = []\n",
    "    try:\n",
    "        comet_exp.set_name(comet_exp_name + \"_\" + sweep_config + \"_\" + str(uuid.uuid4())[:3])\n",
    "        for fold_idx, (tr_idx, va_idx) in enumerate(sgkf.split(X, y, groups)):\n",
    "                score = train_one_fold(\n",
    "                    ds_tr_view=ds_tr_view,\n",
    "                    ds_va_view=ds_va_view,\n",
    "                    tr_idx=tr_idx,\n",
    "                    va_idx=va_idx,\n",
    "                    fold_idx=fold_idx,\n",
    "                    device=\"cuda\",\n",
    "                    comet_exp = comet_exp,\n",
    "                    curr_fold = fold_idx,\n",
    "                    **train_kwargs,\n",
    "                )\n",
    "                if \"plot_imgs\" in train_kwargs and train_kwargs[\"plot_imgs\"]:\n",
    "                    return None, None, None\n",
    "                fold_scores.append(score)\n",
    "    except Exception as e:\n",
    "        print(f\"Fold {fold_idx} failed with exception: {e}\")\n",
    "    finally:\n",
    "        if comet_exp is not None:\n",
    "            comet_exp.end()\n",
    "\n",
    "    fold_scores = np.array(fold_scores, dtype=np.float32)\n",
    "    mean = float(fold_scores.mean())\n",
    "    std = float(fold_scores.std(ddof=0))\n",
    "\n",
    "    print(\"\\nCV summary\")\n",
    "    for i, s in enumerate(fold_scores.tolist()):\n",
    "        print(f\"  fold {i}: {s:.4f}\")\n",
    "    print(f\"  mean ± std: {mean:.4f} ± {std:.4f}\")\n",
    "    return fold_scores, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f84208",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_biomass = BiomassBaseCached(WIDE_DF, img_size=IMG_SIZE)\n",
    "assert RUN_SWEEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3710d",
   "metadata": {},
   "source": [
    "# Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b247eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfms_0():\n",
    "    return T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomChoice([\n",
    "            T.Lambda(lambda x: x),\n",
    "            T.RandomRotation((90, 90)),\n",
    "            T.RandomRotation((180, 180)),\n",
    "            T.RandomRotation((270, 270)),\n",
    "        ]),\n",
    "        T.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.035),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd8080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/v1kstrand/cv5-9e96/47d36f8e6a41406783f68c8d13cc5ce0\n",
      "\n",
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Error logging git-related information\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da3e59a9ec648daa72d921e2c64bda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9bd5daef1d4a98b3e5662c329efd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509095b870cf40f9acf4caa7547f8543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5750a9bb4c624943937e6f08d4f4d0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1badb5ba944436a9050bf59ea1a114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306868d8553d4810a528f0e21e2c0e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b322ae44d124deeb2e3e04b0f8adc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c62f1a27cc416fb6092313b2bef5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b17c258c074068a152a7b2a9a35d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14b7e3acb5c4bbfb83daa5d078c5027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : cv5-9e96_{'num_neck': 1, 'head_depth': 4, 'tfms_fn': <function get_tfms_0 at 0x7f68a6c80a60>}_43b\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/v1kstrand/cv5-9e96/47d36f8e6a41406783f68c8d13cc5ce0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_0 [15] : (0.08894143998622894, 0.18911533057689667)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_1 [15] : (0.0808490738272667, 0.19342468678951263)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_2 [15] : (0.07483459264039993, 0.15528805553913116)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_3 [15] : (0.04137527197599411, 0.09215528517961502)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_4 [15] : (0.06549517810344696, 0.18735960125923157)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_0 [7]         : (0.4471535086631775, 0.6122885942459106)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_1 [7]         : (0.703782320022583, 0.7269006371498108)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_2 [7]         : (0.8758941888809204, 0.8918581008911133)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_3 [7]         : (0.713024377822876, 0.7193715572357178)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_4 [7]         : (0.6233887076377869, 0.6671715974807739)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_0 [19]     : (0.08823763579130173, 0.24531760811805725)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_1 [18]     : (0.07938145101070404, 0.2571617364883423)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_2 [21]     : (0.06256403028964996, 0.2905959188938141)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_3 [33]     : (0.042701441794633865, 0.35354024171829224)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_4 [24]     : (0.0804828628897667, 0.31356117129325867)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_0 [19]        : (0.45834243297576904, 0.6352850794792175)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_1 [18]        : (0.5428601503372192, 0.7381507754325867)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_2 [21]        : (0.617769718170166, 0.8805564641952515)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_3 [33]        : (0.36721765995025635, 0.7106078267097473)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_4 [24]        : (0.32384592294692993, 0.7139945030212402)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : cv5-9e96_{'num_neck': 1, 'head_depth': 4, 'tfms_fn': <function get_tfms_0 at 0x7f68a6c80a60>}_43b\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 30.15 KB/30.15 KB\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV summary\n",
      "  fold 0: 0.6072\n",
      "  fold 1: 0.7279\n",
      "  fold 2: 0.8853\n",
      "  fold 3: 0.7125\n",
      "  fold 4: 0.6563\n",
      "  mean ± std: 0.7179 ± 0.0940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/v1kstrand/cv5-9e96/6844c46295c24ad082f681b2a5d28679\n",
      "\n",
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Error logging git-related information\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ade920703624227be3fb9f7accac5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c022da640b14cbfb69980618605e06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd086d4b0360434cbf1bd7a3a8bc40bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb9ad8db92248c7b9daa72f89eee654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34c08bf86894084924ac0ee090eb874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b56277c9a684847a36beab0c1c008c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd98f5d279e4422caa2e23f979fce0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38447c2839ce478f9949f5142c99eee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5316da1156843d7a773b2dea1455ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e21304b36c34b248bbda0f88ad454be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : cv5-9e96_{'num_neck': 1, 'head_depth': 5, 'tfms_fn': <function get_tfms_0 at 0x7f68a6c80a60>}_3bf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/v1kstrand/cv5-9e96/6844c46295c24ad082f681b2a5d28679\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_0 [15] : (0.0854143500328064, 0.21025492250919342)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_1 [15] : (0.07407134026288986, 0.181295245885849)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_2 [15] : (0.020146487280726433, 0.030466768890619278)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_3 [15] : (0.07676973938941956, 0.20657697319984436)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_4 [15] : (0.058716267347335815, 0.1263621300458908)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_0 [7]         : (0.5388344526290894, 0.6013842821121216)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_1 [7]         : (0.723956286907196, 0.7531421184539795)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_2 [7]         : (0.8319406509399414, 0.8495235443115234)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_3 [7]         : (0.7124006748199463, 0.7224041223526001)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_4 [7]         : (0.6985982656478882, 0.7157337069511414)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_0 [21]     : (0.08160840719938278, 0.4849162995815277)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_1 [20]     : (0.07504294067621231, 0.3475022614002228)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_2 [61]     : (0.020742064341902733, 0.33890143036842346)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_3 [22]     : (0.08002446591854095, 0.4153173267841339)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_4 [30]     : (0.06660719215869904, 0.418285995721817)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_0 [21]        : (0.25386059284210205, 0.6069549918174744)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_1 [20]        : (0.5373092293739319, 0.763505756855011)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_2 [61]        : (0.4824349284172058, 0.878094494342804)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_3 [22]        : (-0.03321564197540283, 0.7193105220794678)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_4 [30]        : (0.47386300563812256, 0.7449243068695068)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : cv5-9e96_{'num_neck': 1, 'head_depth': 5, 'tfms_fn': <function get_tfms_0 at 0x7f68a6c80a60>}_3bf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV summary\n",
      "  fold 0: 0.5875\n",
      "  fold 1: 0.7355\n",
      "  fold 2: 0.8521\n",
      "  fold 3: 0.7177\n",
      "  fold 4: 0.7036\n",
      "  mean ± std: 0.7193 ± 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/v1kstrand/cv5-9e96/a7cea6df28f143ccbf613eadd4e37737\n",
      "\n",
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Error logging git-related information\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cfd3b860b647c7bd9fec6a00369fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9692001cecbe41a9b1a22d4b104a0347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a8a06165064a0c803e358a8ed574f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca531c6355cb4231a8507a6a9245bc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6a166f596b4db79554996826324d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45e6a2a89ba4cdaa3797c987b8808cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1bfb18757a4e85bbd7fead0175f4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6345a838cf04a9493338b6e26608d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d79cb44c2964dbd89d3cf5195404ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30b5d231f7f4c6ab414ed7f3f8f1721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : cv5-9e96_{'num_neck': 2, 'head_depth': 4, 'tfms_fn': <function get_tfms_0 at 0x7f68a6c80a60>}_6c5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/v1kstrand/cv5-9e96/a7cea6df28f143ccbf613eadd4e37737\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_0 [15] : (0.0671190395951271, 0.1777181625366211)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_1 [15] : (0.0802803635597229, 0.21668942272663116)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_2 [15] : (0.05535123869776726, 0.13715574145317078)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_3 [15] : (0.03953289985656738, 0.07735414803028107)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_train_loss_4 [15] : (0.07006355375051498, 0.16676172614097595)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_0 [7]         : (0.5512059926986694, 0.6099272966384888)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_1 [7]         : (0.7141550779342651, 0.7471787929534912)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_2 [7]         : (0.7169779539108276, 0.8372758626937866)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_3 [7]         : (0.6460973024368286, 0.6686108112335205)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     swa_wR2_4 [7]         : (0.5928331613540649, 0.6965687870979309)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_0 [23]     : (0.0637630894780159, 0.2617444097995758)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_1 [18]     : (0.09006340801715851, 0.2893240749835968)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_2 [24]     : (0.06179887428879738, 0.30855756998062134)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_3 [33]     : (0.040548522025346756, 0.3439260721206665)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_4 [24]     : (0.07372002303600311, 0.30513468384742737)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_0 [23]        : (0.27202874422073364, 0.6440110206604004)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_1 [18]        : (0.43358540534973145, 0.741671085357666)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_2 [24]        : (0.6368951797485352, 0.872748613357544)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_3 [33]        : (0.42161232233047485, 0.685790479183197)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_wR2_4 [24]        : (0.3821237087249756, 0.7336575984954834)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : cv5-9e96_{'num_neck': 2, 'head_depth': 4, 'tfms_fn': <function get_tfms_0 at 0x7f68a6c80a60>}_6c5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV summary\n",
      "  fold 0: 0.5938\n",
      "  fold 1: 0.7468\n",
      "  fold 2: 0.8391\n",
      "  fold 3: 0.6660\n",
      "  fold 4: 0.6950\n",
      "  mean ± std: 0.7081 ± 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/v1kstrand/cv5-9e96/ce77217fa1494bbf8d4ff1987c460f1a\n",
      "\n",
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Error logging git-related information\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861b0891235441d59a8cbb29eddaa1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab706b3d7688485793cb7fe08af439dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfda3d13a9cf426d810ae726505e35f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6667ccfba4dc4ef18fa28cf36f06a76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04d10349125444a834c592f6066567e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a10a7de10542e2bd14d6e9aee2fb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1d44e9083b4028aa11f44def096731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dd99160d944ebd92d01d9ba9f37fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_kwargs = dict(\n",
    "    dataset=dataset_biomass,\n",
    "    wide_df=WIDE_DF,\n",
    "    backbone=MODEL,\n",
    "    epochs=80,\n",
    "    batch_size=64,\n",
    "    wd=3e-3,\n",
    "    head_hidden=2048,\n",
    "    head_drop=0.1,\n",
    "    head_depth=5,\n",
    "    plot_imgs=False,\n",
    "    early_stopping=15,\n",
    "    comet_exp_name=\"cv5\",\n",
    ")\n",
    "\n",
    "sweeps = [\n",
    "    dict(num_neck=1, head_depth=4, tfms_fn=get_tfms_0),\n",
    "    dict(num_neck=1, head_depth=5, tfms_fn=get_tfms_0),\n",
    "    dict(num_neck=2, head_depth=4, tfms_fn=get_tfms_0),\n",
    "    dict(num_neck=2, head_depth=5, tfms_fn=get_tfms_0),\n",
    "\n",
    "]\n",
    "\n",
    "sweep_id = str(uuid.uuid4())[:4]\n",
    "for sweep in sweeps: \n",
    "    new_train_kwargs = train_kwargs.copy() \n",
    "    for k, v in sweep.items(): \n",
    "        new_train_kwargs[k] = v\n",
    "    new_train_kwargs[\"comet_exp_name\"] += f\"-{sweep_id}\"\n",
    "    new_train_kwargs[\"sweep_config\"] = str(sweep)\n",
    "    scores, mean, std = run_groupkfold_cv(**new_train_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edd278",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.7.1 (cu118)",
   "language": "python",
   "name": "pt27cu118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
