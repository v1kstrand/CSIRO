{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSIRO Kaggle Submission Notebook\n",
        "\n",
        "This notebook assumes offline submission (no internet). Edit the flags below to match your Kaggle inputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "INPUT_ROOT = \"/kaggle/input\"\n",
        "\n",
        "def find_path(patterns, must_exist=True):\n",
        "    \"\"\"Return first match under /kaggle/input for any glob pattern in patterns.\"\"\"\n",
        "    for pat in patterns:\n",
        "        hits = glob.glob(os.path.join(INPUT_ROOT, pat))\n",
        "        if hits:\n",
        "            return hits[0]\n",
        "    if must_exist:\n",
        "        raise FileNotFoundError(f\"No matches for {patterns} under {INPUT_ROOT}\")\n",
        "    return None\n",
        "\n",
        "DETECTED_CSIRO_INPUT = find_path([\n",
        "    \"*csiro*code*\", \"*csiro*repo*\", \"*biomass*code*\", \"*vikstrand*ai*\", \"*csiro*\"\n",
        "], must_exist=False)\n",
        "\n",
        "DETECTED_DINO_REPO = find_path([\n",
        "    \"*dinov3*\", \"*dino*v3*\", \"*dino*repo*\"\n",
        "], must_exist=False)\n",
        "\n",
        "print(\"DETECTED_CSIRO_INPUT:\", DETECTED_CSIRO_INPUT)\n",
        "print(\"DETECTED_DINO_REPO:\", DETECTED_DINO_REPO)\n",
        "print(\"INPUT DIRS:\", os.listdir(INPUT_ROOT)[:30])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8fccf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global flags (edit these)\n",
        "CSIRO_INPUT = DETECTED_CSIRO_INPUT\n",
        "DINO_REPO = DETECTED_DINO_REPO or \"/kaggle/input/dinov3\"\n",
        "TEST_CSV = \"/kaggle/input/<dataset>/test.csv\"\n",
        "IMAGE_ROOT = \"/kaggle/input/<dataset>/test_images\"\n",
        "IMAGE_PATH_COL = \"image_path\"\n",
        "IMAGE_ID_COL = \"image_id\"\n",
        "WEIGHTS_PATH = \"/kaggle/input/<weights-dataset>/ensemble_states.pt\"\n",
        "DINO_WEIGHTS = \"/kaggle/input/dinov3/weights/dinov3_vitb16_pretrain.pth\"\n",
        "MODEL_SIZE = \"b\"\n",
        "PLUS = \"\"\n",
        "IMG_SIZE = 512\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "DEVICE = \"cuda\"\n",
        "TTA_ROT90 = True\n",
        "TTA_AGG = \"mean\"\n",
        "ENS_AGG = \"mean\"\n",
        "OUTPUT_PATH = \"/kaggle/working/submission.csv\"\n",
        "\n",
        "if IMAGE_ROOT == \"\":\n",
        "    IMAGE_ROOT = None\n",
        "\n",
        "DETECTED_COMP = find_path([\n",
        "    \"*csiro*image2biomass*\", \"*image2biomass*\", \"*biomass*\"\n",
        "], must_exist=False)\n",
        "if DETECTED_COMP:\n",
        "    cand_test_csv = os.path.join(DETECTED_COMP, \"test.csv\")\n",
        "    cand_test_img = os.path.join(DETECTED_COMP, \"test_images\")\n",
        "    if os.path.exists(cand_test_csv):\n",
        "        TEST_CSV = cand_test_csv\n",
        "    if os.path.exists(cand_test_img):\n",
        "        IMAGE_ROOT = cand_test_img\n",
        "\n",
        "DETECTED_W = find_path([\n",
        "    \"*weights*\", \"*ensemble*\", \"*ckpt*\", \"*checkpoints*\"\n",
        "], must_exist=False)\n",
        "if DETECTED_W:\n",
        "    hits = glob.glob(os.path.join(DETECTED_W, \"**\", \"ensemble_states.pt\"), recursive=True)\n",
        "    if hits:\n",
        "        WEIGHTS_PATH = hits[0]\n",
        "\n",
        "if DINO_REPO is not None and (DINO_WEIGHTS is None or not os.path.exists(DINO_WEIGHTS)):\n",
        "    hits = glob.glob(os.path.join(DINO_REPO, \"**\", \"*.pth\"), recursive=True)\n",
        "    if len(hits) == 1:\n",
        "        DINO_WEIGHTS = hits[0]\n",
        "    elif len(hits) > 1:\n",
        "        print(\"Found DINO weights candidates:\", hits[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "843497a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if DINO_REPO is None:\n",
        "    raise RuntimeError(\"DINO_REPO not found; attach the dinov3 dataset input.\")\n",
        "if not os.path.exists(DINO_REPO):\n",
        "    raise FileNotFoundError(DINO_REPO)\n",
        "if not os.path.exists(TEST_CSV):\n",
        "    raise FileNotFoundError(TEST_CSV)\n",
        "if not os.path.exists(WEIGHTS_PATH):\n",
        "    raise FileNotFoundError(WEIGHTS_PATH)\n",
        "if DINO_WEIGHTS is None or not os.path.exists(DINO_WEIGHTS):\n",
        "    raise FileNotFoundError(str(DINO_WEIGHTS))\n",
        "if IMAGE_ROOT is not None and not os.path.exists(IMAGE_ROOT):\n",
        "    raise FileNotFoundError(IMAGE_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8331af",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "if CSIRO_INPUT is not None:\n",
        "    sys.path.insert(0, CSIRO_INPUT)\n",
        "if DINO_REPO is not None:\n",
        "    sys.path.insert(0, DINO_REPO)\n",
        "\n",
        "try:\n",
        "    import csiro\n",
        "    print(\"csiro import OK from:\", csiro.__file__)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Could not import csiro package. Attach the dataset containing the csiro/ folder.\"\n",
        "    ) from e\n",
        "\n",
        "from csiro.config import TARGETS, dino_hub_name\n",
        "from csiro.transforms import PadToSquare, post_tfms\n",
        "from csiro.train import predict_ensemble\n",
        "\n",
        "if DEVICE.startswith(\"cuda\") and not torch.cuda.is_available():\n",
        "    DEVICE = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16dee90",
      "metadata": {},
      "outputs": [],
      "source": [
        "ckpt = torch.load(WEIGHTS_PATH, map_location=\"cpu\")\n",
        "states = ckpt[\"states\"] if isinstance(ckpt, dict) and \"states\" in ckpt else ckpt\n",
        "\n",
        "backbone = torch.hub.load(\n",
        "    DINO_REPO,\n",
        "    dino_hub_name(model_size=str(MODEL_SIZE), plus=str(PLUS)),\n",
        "    source=\"local\",\n",
        "    weights=DINO_WEIGHTS,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5824f397",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, root, img_col, img_size):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root = root\n",
        "        self.img_col = img_col\n",
        "        self.pre = T.Compose([\n",
        "            T.Lambda(lambda im: im.convert(\"RGB\")),\n",
        "            PadToSquare(fill=0),\n",
        "            T.Resize((int(img_size), int(img_size)), antialias=True),\n",
        "        ])\n",
        "        self.post = post_tfms()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        p = self.df.loc[i, self.img_col]\n",
        "        if self.root and not os.path.isabs(p):\n",
        "            p = os.path.join(self.root, p)\n",
        "        with Image.open(p) as im:\n",
        "            im = self.pre(im).copy()\n",
        "        x = self.post(im)\n",
        "        return x\n",
        "\n",
        "df = pd.read_csv(TEST_CSV)\n",
        "if IMAGE_PATH_COL not in df.columns:\n",
        "    raise KeyError(f\"Missing column: {IMAGE_PATH_COL}\")\n",
        "if IMAGE_ID_COL not in df.columns:\n",
        "    df[IMAGE_ID_COL] = df[IMAGE_PATH_COL].apply(\n",
        "        lambda p: os.path.splitext(os.path.basename(p))[0]\n",
        "    )\n",
        "\n",
        "print(\"test_df columns:\", list(df.columns))\n",
        "print(df.head(3))\n",
        "\n",
        "dataset = TestDataset(df, IMAGE_ROOT, IMAGE_PATH_COL, IMG_SIZE)\n",
        "preds = predict_ensemble(\n",
        "    dataset,\n",
        "    states,\n",
        "    backbone,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    device=DEVICE,\n",
        "    tta_rot90=TTA_ROT90,\n",
        "    tta_agg=TTA_AGG,\n",
        "    ens_agg=ENS_AGG,\n",
        ")\n",
        "print(\"preds grams min/max:\", float(preds.min()), float(preds.max()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176fcb35",
      "metadata": {},
      "outputs": [],
      "source": [
        "preds_np = preds.detach().float().cpu().numpy()\n",
        "preds_np = preds_np.clip(min=0)\n",
        "assert preds_np.shape[0] == len(df), (preds_np.shape, len(df))\n",
        "assert preds_np.shape[1] == len(TARGETS), (preds_np.shape, len(TARGETS))\n",
        "\n",
        "SAMPLE_SUB = os.path.join(os.path.dirname(TEST_CSV), \"sample_submission.csv\")\n",
        "if os.path.exists(SAMPLE_SUB):\n",
        "    sub = pd.read_csv(SAMPLE_SUB)\n",
        "    pred_map = {}\n",
        "    ids = df[IMAGE_ID_COL].astype(str).tolist()\n",
        "    for i, img_id in enumerate(ids):\n",
        "        for t_idx, t_name in enumerate(TARGETS):\n",
        "            pred_map[f\"{img_id}__{t_name}\"] = float(preds_np[i, t_idx])\n",
        "    sub[\"target\"] = sub[\"sample_id\"].map(pred_map).astype(float)\n",
        "    if sub[\"target\"].isna().any():\n",
        "        raise ValueError(\"sample_submission mapping produced NaNs\")\n",
        "else:\n",
        "    ids = df[IMAGE_ID_COL].astype(str).tolist()\n",
        "    rows = []\n",
        "    for i, img_id in enumerate(ids):\n",
        "        for t_idx, t_name in enumerate(TARGETS):\n",
        "            rows.append((f\"{img_id}__{t_name}\", float(preds_np[i, t_idx])))\n",
        "    sub = pd.DataFrame(rows, columns=[\"sample_id\", \"target\"])\n",
        "\n",
        "sub.to_csv(OUTPUT_PATH, index=False)\n",
        "print(sub.head())\n",
        "print(\"rows:\", len(sub))\n",
        "\n",
        "import numpy as np\n",
        "sub = pd.read_csv(OUTPUT_PATH)\n",
        "assert list(sub.columns) == [\"sample_id\", \"target\"]\n",
        "assert len(sub) == 5 * len(df)\n",
        "assert np.isfinite(sub[\"target\"].values).all()\n",
        "assert not sub[\"target\"].isna().any()\n",
        "print(sub.head(10))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
