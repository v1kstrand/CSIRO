{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f8a769d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Must be set before any CUDA context is created\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import torch\n",
        "\n",
        "# Determinism / precision\n",
        "torch.backends.cuda.matmul.allow_tf32 = False\n",
        "torch.backends.cudnn.allow_tf32 = False\n",
        "torch.set_float32_matmul_precision(\"highest\")\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6d6fb660",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T16:06:25.103493Z",
          "iopub.status.busy": "2025-12-22T16:06:25.103188Z",
          "iopub.status.idle": "2025-12-22T16:06:25.110594Z",
          "shell.execute_reply": "2025-12-22T16:06:25.109863Z",
          "shell.execute_reply.started": "2025-12-22T16:06:25.103465Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# 0) CONFIG (edit these)\n",
        "# -------------------------\n",
        "import os, sys\n",
        "\n",
        "# Project code (must contain the csiro package)\n",
        "CSIRO_CODE_DIR = \"/notebooks/CSIRO\"\n",
        "\n",
        "# DINOv3 repo/code dir (must contain hubconf.py)\n",
        "DINO_REPO = \"/notebooks/dinov3\"\n",
        "\n",
        "# DINOv3 pretrained backbone weights (.pth)\n",
        "DINO_WEIGHTS = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain.pth\"\n",
        "\n",
        "# Ensemble checkpoint produced by CV (dict with key 'states')\n",
        "WEIGHTS_PATH = \"/notebooks/kaggle/csiro/weights/cv5_v1_f0a.pt\"\n",
        "\n",
        "# Competition data\n",
        "COMP_ROOT = \"/notebooks/kaggle/csiro/\"\n",
        "TEST_CSV = f\"{COMP_ROOT}/test.csv\"\n",
        "# IMPORTANT: test.csv image_path values look like \"test/IDxxxx.jpg\", so IMAGE_ROOT should be COMP_ROOT\n",
        "IMAGE_ROOT = COMP_ROOT\n",
        "\n",
        "# Inference params\n",
        "IMG_SIZE = 512\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "DEVICE = \"cuda\"  # or \"cpu\"\n",
        "\n",
        "# TTA / ensemble knobs\n",
        "TTA_ROT90 = True\n",
        "TTA_AGG = \"mean\"\n",
        "ENS_AGG = \"mean\"\n",
        "\n",
        "OUTPUT_PATH = \"/notebooks/kaggle/csiro/sub/submission.csv\"\n",
        "\n",
        "# --- Env vars expected by csiro.config (no defaults) ---\n",
        "os.environ[\"TORCH_HOME\"] = \"notebooks/kaggle/working/torch_home\"\n",
        "os.environ[\"DINO_WB\"] = \"https://dinov3.llamameta.net/dinov3_vitb16/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
        "os.environ[\"DINO_WL\"] = \"https://dinov3.llamameta.net/dinov3_vitl16/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
        "os.environ[\"DINO_WL_plus\"] = \"https://dinov3.llamameta.net/dinov3_vith16plus/dinov3_vith16plus_pretrain_lvd1689m-7c1da9a5.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
        "os.environ[\"DEFAULT_DINO_REPO_DIR\"] = DINO_REPO\n",
        "os.environ[\"DEFAULT_DATA_ROOT\"] = COMP_ROOT\n",
        "\n",
        "sys.path.insert(0, CSIRO_CODE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f059a0b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T16:06:28.456077Z",
          "iopub.status.busy": "2025-12-22T16:06:28.455482Z",
          "iopub.status.idle": "2025-12-22T16:06:36.560952Z",
          "shell.execute_reply": "2025-12-22T16:06:36.560266Z",
          "shell.execute_reply.started": "2025-12-22T16:06:28.456038Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TARGETS: ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# 1) Imports\n",
        "# -------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "import csiro\n",
        "from csiro.config import TARGETS, dino_hub_name, DEFAULT_MODEL_SIZE, DEFAULT_PLUS\n",
        "from csiro.transforms import PadToSquare, post_tfms\n",
        "from csiro.eval import predict_ensemble\n",
        "\n",
        "print(\"TARGETS:\", TARGETS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1bae8288-a8ee-4aa9-b8ed-047facc7229a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T16:06:38.306803Z",
          "iopub.status.busy": "2025-12-22T16:06:38.306347Z",
          "iopub.status.idle": "2025-12-22T16:06:38.311741Z",
          "shell.execute_reply": "2025-12-22T16:06:38.311204Z",
          "shell.execute_reply.started": "2025-12-22T16:06:38.306776Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "# Create checkpoints dir\n",
        "ckpt_dir = Path(torch.hub.get_dir()) / \"checkpoints\"\n",
        "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Symlink the weight file from /kaggle/input (read-only) into the hub cache\n",
        "src = Path(DINO_WEIGHTS)                  # /kaggle/input/.../dinov3_vitb16_pretrain.pth\n",
        "dst = ckpt_dir / src.name                 # /kaggle/working/torch_hub/checkpoints/dinov3_vitb16_pretrain.pth\n",
        "\n",
        "if not dst.exists():\n",
        "    dst.symlink_to(src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c6adc9d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T16:06:41.340779Z",
          "iopub.status.busy": "2025-12-22T16:06:41.340477Z",
          "iopub.status.idle": "2025-12-22T16:06:56.823323Z",
          "shell.execute_reply": "2025-12-22T16:06:56.822550Z",
          "shell.execute_reply.started": "2025-12-22T16:06:41.340752Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded states <class 'list'>\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# 2) Load checkpoint + backbone\n",
        "# -------------------------\n",
        "ckpt = torch.load(WEIGHTS_PATH, map_location=\"cpu\", weights_only=False)\n",
        "if isinstance(ckpt, dict) and \"states\" in ckpt:\n",
        "    states = ckpt[\"states\"]\n",
        "else:\n",
        "    states = ckpt\n",
        "\n",
        "sys.path.insert(0, DINO_REPO)\n",
        "backbone = torch.hub.load(\n",
        "    DINO_REPO,\n",
        "    dino_hub_name(model_size=str(DEFAULT_MODEL_SIZE), plus=str(DEFAULT_PLUS)),\n",
        "    source=\"local\",\n",
        "    weights=DINO_WEIGHTS,\n",
        ").cuda()\n",
        "\n",
        "backbone.eval()\n",
        "print(\"Loaded states\", type(states))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7b9331d4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[ 3.9159, -0.5923,  2.9785,  3.7281,  4.3917]], device='cuda:0')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from csiro.eval import load_dinov3_regressor_from_pt as load_model\n",
        "from csiro.eval import forward_trainable_random\n",
        "\n",
        "\n",
        "model = load_model(WEIGHTS_PATH, backbone=backbone)\n",
        "forward_trainable_random(model, seed=420, device=\"cuda\", head_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b94b585c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T16:06:59.199273Z",
          "iopub.status.busy": "2025-12-22T16:06:59.198474Z",
          "iopub.status.idle": "2025-12-22T16:06:59.233236Z",
          "shell.execute_reply": "2025-12-22T16:06:59.232626Z",
          "shell.execute_reply.started": "2025-12-22T16:06:59.199238Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test.csv columns: ['sample_id', 'image_path', 'target_name']\n",
            "                    sample_id             image_path   target_name\n",
            "0  ID1001187975__Dry_Clover_g  test/ID1001187975.jpg  Dry_Clover_g\n",
            "1    ID1001187975__Dry_Dead_g  test/ID1001187975.jpg    Dry_Dead_g\n",
            "2   ID1001187975__Dry_Green_g  test/ID1001187975.jpg   Dry_Green_g\n",
            "rows (long): 5 unique images: 1\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# 3) Read test.csv (long format)\n",
        "# -------------------------\n",
        "df = pd.read_csv(TEST_CSV)\n",
        "print(\"test.csv columns:\", list(df.columns))\n",
        "print(df.head(3))\n",
        "\n",
        "IMAGE_PATH_COL = \"image_path\"\n",
        "TARGET_NAME_COL = \"target_name\"\n",
        "SAMPLE_ID_COL = \"sample_id\"\n",
        "\n",
        "if IMAGE_PATH_COL not in df.columns:\n",
        "    raise ValueError(f\"Expected column {IMAGE_PATH_COL} in test.csv\")\n",
        "if TARGET_NAME_COL not in df.columns:\n",
        "    raise ValueError(f\"Expected column {TARGET_NAME_COL} in test.csv\")\n",
        "\n",
        "df_img = df.drop_duplicates(subset=[IMAGE_PATH_COL]).reset_index(drop=True)\n",
        "print(\"rows (long):\", len(df), \"unique images:\", len(df_img))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b6facce5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T16:07:01.641107Z",
          "iopub.status.busy": "2025-12-22T16:07:01.640799Z",
          "iopub.status.idle": "2025-12-22T16:07:08.236309Z",
          "shell.execute_reply": "2025-12-22T16:07:08.235181Z",
          "shell.execute_reply.started": "2025-12-22T16:07:01.641080Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preds shape: (1, 5)\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# 4) Dataset + inference\n",
        "# -------------------------\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, root, img_col, img_size):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root = root\n",
        "        self.img_col = img_col\n",
        "        self.pre = T.Compose([\n",
        "            T.Lambda(lambda im: im.convert(\"RGB\")),\n",
        "            PadToSquare(fill=0),\n",
        "            T.Resize((int(img_size), int(img_size)), antialias=True),\n",
        "            post_tfms(),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        rel = self.df.loc[i, self.img_col]\n",
        "        p = os.path.join(self.root, rel) if self.root else rel\n",
        "        with Image.open(p) as im:\n",
        "            x = self.pre(im)\n",
        "        return x\n",
        "\n",
        "ds = TestDataset(df_img, IMAGE_ROOT, IMAGE_PATH_COL, IMG_SIZE)\n",
        "preds = predict_ensemble(\n",
        "    ds,\n",
        "    states=states,\n",
        "    backbone=backbone,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    device=DEVICE,\n",
        "    tta_rot90=TTA_ROT90,\n",
        "    tta_agg=TTA_AGG,\n",
        "    ens_agg=ENS_AGG,\n",
        ")\n",
        "\n",
        "preds = preds.detach().cpu()\n",
        "print(\"preds shape:\", tuple(preds.shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3fde7754",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-22T16:07:08.636105Z",
          "iopub.status.busy": "2025-12-22T16:07:08.635781Z",
          "iopub.status.idle": "2025-12-22T16:07:08.655181Z",
          "shell.execute_reply": "2025-12-22T16:07:08.654545Z",
          "shell.execute_reply.started": "2025-12-22T16:07:08.636070Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote /notebooks/kaggle/csiro/sub/submission.csv\n",
            "                    sample_id      target\n",
            "0  ID1001187975__Dry_Clover_g    0.000000\n",
            "1    ID1001187975__Dry_Dead_g   18.312599\n",
            "2   ID1001187975__Dry_Green_g  332.788330\n",
            "3   ID1001187975__Dry_Total_g  238.660995\n",
            "4         ID1001187975__GDM_g  176.639587\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# 5) Build submission (long format)\n",
        "# -------------------------\n",
        "target_to_idx = {t: i for i, t in enumerate(TARGETS)}\n",
        "preds_np = preds.numpy()\n",
        "\n",
        "pred_by_path = {\n",
        "    df_img.loc[i, IMAGE_PATH_COL]: preds_np[i]\n",
        "    for i in range(len(df_img))\n",
        "}\n",
        "\n",
        "if SAMPLE_ID_COL in df.columns:\n",
        "    sample_ids = df[SAMPLE_ID_COL].astype(str)\n",
        "else:\n",
        "    image_ids = df[IMAGE_PATH_COL].apply(lambda p: os.path.splitext(os.path.basename(p))[0])\n",
        "    sample_ids = image_ids + \"__\" + df[TARGET_NAME_COL].astype(str)\n",
        "\n",
        "targets = []\n",
        "for i, row in df.iterrows():\n",
        "    p = row[IMAGE_PATH_COL]\n",
        "    t_name = row[TARGET_NAME_COL]\n",
        "    if t_name not in target_to_idx:\n",
        "        raise ValueError(f\"Unknown target_name: {t_name}\")\n",
        "    vec = pred_by_path[p]\n",
        "    targets.append(float(vec[target_to_idx[t_name]]))\n",
        "\n",
        "sub = pd.DataFrame({\n",
        "    \"sample_id\": sample_ids.values,\n",
        "    \"target\": np.asarray(targets, dtype=np.float32),\n",
        "})\n",
        "\n",
        "assert len(sub) == len(df)\n",
        "assert list(sub.columns) == [\"sample_id\", \"target\"]\n",
        "assert np.isfinite(sub[\"target\"].values).all()\n",
        "\n",
        "print(\"Wrote\", OUTPUT_PATH)\n",
        "print(sub.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "da979a58",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from csiro.model import DINOv3Regressor\n",
        "\n",
        "def build_ensemble_from_states(states, backbone, device=\"cuda\"):\n",
        "    if states and isinstance(states[0], list):\n",
        "        states = [s for fold in states for s in fold]\n",
        "\n",
        "    models = []\n",
        "    for s in states:\n",
        "        model = DINOv3Regressor(\n",
        "            backbone,\n",
        "            hidden=int(s[\"head_hidden\"]),\n",
        "            drop=float(s[\"head_drop\"]),\n",
        "            depth=int(s[\"head_depth\"]),\n",
        "            num_neck=int(s[\"num_neck\"]),\n",
        "        ).to(device)\n",
        "\n",
        "        parts = s.get(\"parts\", s)\n",
        "        for name in (\"neck\", \"head\", \"norm\"):\n",
        "            part = getattr(model, name, None)\n",
        "            if part is not None and name in parts:\n",
        "                part.load_state_dict(parts[name], strict=True)\n",
        "\n",
        "        if hasattr(model, \"set_train\"):\n",
        "            model.set_train(False)\n",
        "        model.eval()\n",
        "        models.append(model)\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "models = build_ensemble_from_states(states, backbone, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ec71bfa5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def neck_head_only_output_dtype(\n",
        "    model,\n",
        "    *,\n",
        "    feat_dim=None,\n",
        "    tokens_len=197,\n",
        "    device=\"cuda\",\n",
        "    seed=1234,\n",
        "    dtype=torch.float32,\n",
        "):\n",
        "    if isinstance(model, list):\n",
        "        model = model[0]\n",
        "    if hasattr(model, \"set_train\"):\n",
        "        model.set_train(False)\n",
        "    model.eval()\n",
        "    model = model.to(device=device, dtype=dtype)\n",
        "\n",
        "    if feat_dim is None:\n",
        "        feat_dim = int(model.feat_dim)\n",
        "\n",
        "    g = torch.Generator(device=device).manual_seed(seed)\n",
        "    x = torch.rand(\n",
        "        1, int(tokens_len), int(feat_dim),\n",
        "        generator=g, device=device, dtype=dtype\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tokens = x\n",
        "        for block in model.neck:\n",
        "            try:\n",
        "                tokens = block(tokens, None)\n",
        "            except TypeError:\n",
        "                tokens = block(tokens)\n",
        "        cls = tokens[:, 0, :]\n",
        "        cls = model.norm(cls)\n",
        "        y = model.head(cls)\n",
        "\n",
        "    return y  # tensor in the requested dtype\n",
        "\n",
        "\n",
        "out = neck_head_only_output_dtype(models, device=\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b51d9b6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def backbone_only_output_dtype(\n",
        "    backbone,\n",
        "    *,\n",
        "    img_size=512,\n",
        "    device=\"cuda\",\n",
        "    seed=1234,\n",
        "    dtype=torch.float32,\n",
        "):\n",
        "    bb = backbone.to(device=device, dtype=dtype)\n",
        "    bb.eval()\n",
        "\n",
        "    g = torch.Generator(device=device).manual_seed(seed)\n",
        "    x = torch.rand(1, 3, int(img_size), int(img_size), generator=g, device=device, dtype=dtype)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = bb(x)\n",
        "\n",
        "    return out  # tensor/dict/tuple (backbone-dependent)\n",
        "\n",
        "\n",
        "out = backbone_only_output_dtype(backbone, device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4deedebf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = out[0][\"x_norm_clstoken\"][0][:30].cpu()\n",
        "b = [ 0.5429,  0.9854,  0.1405, -0.7231,  0.1026, -0.3698, -0.2895, -0.0146,\n",
        "         0.4019, -0.9260, -0.0975, -0.1967, -0.8500, -1.0350,  0.4145,  0.6360,\n",
        "         0.4236, -0.5198,  1.2021, -0.3985,  0.7240, -0.1795, -0.5919,  1.6447,\n",
        "         0.4511, -0.2003, -1.5573, -0.2953, -0.4824,  0.2522]\n",
        "\n",
        "torch.allclose(a, torch.tensor(b), atol=1e-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "6c767273",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "15*6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e4d6f196",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = [ 0.5732,  0.9725,  0.0507, -0.7856,  0.2029, -0.3223, -0.2652,  0.0990,\n",
        "         0.4151, -0.9029, -0.1418, -0.2274, -0.8565, -1.0758,  0.2542,  0.5936,\n",
        "         0.4904, -0.4633,  1.3237, -0.4250,  0.9271, -0.0781, -0.6784,  1.5840,\n",
        "         0.4213, -0.3091, -1.5974, -0.3488, -0.4833,  0.0859]\n",
        "\n",
        "b = [ 0.5732,  0.9725,  0.0507, -0.7856,  0.2030, -0.3223, -0.2652,  0.0990,\n",
        "         0.4150, -0.9029, -0.1418, -0.2274, -0.8565, -1.0758,  0.2541,  0.5936,\n",
        "         0.4904, -0.4633,  1.3237, -0.4250,  0.9271, -0.0781, -0.6784,  1.5840,\n",
        "         0.4213, -0.3091, -1.5974, -0.3488, -0.4833,  0.0858]\n",
        "\n",
        "torch.allclose(torch.tensor(a), torch.tensor(b), atol=1e-4)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 14254895,
          "isSourceIdPinned": false,
          "sourceId": 112509,
          "sourceType": "competition"
        },
        {
          "datasetId": 9096612,
          "sourceId": 14256448,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 9096715,
          "sourceId": 14256574,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": false,
          "modelId": 540716,
          "modelInstanceId": 526672,
          "sourceId": 694510,
          "sourceType": "modelInstanceVersion"
        },
        {
          "isSourceIdPinned": false,
          "modelId": 540735,
          "modelInstanceId": 526691,
          "sourceId": 694536,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
