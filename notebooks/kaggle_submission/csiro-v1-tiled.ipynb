{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:04:36.571507Z",
     "iopub.status.busy": "2025-12-28T19:04:36.570808Z",
     "iopub.status.idle": "2025-12-28T19:04:36.581747Z",
     "shell.execute_reply": "2025-12-28T19:04:36.580925Z",
     "shell.execute_reply.started": "2025-12-28T19:04:36.571479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGETS: ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n",
      "Downloading: \"file:///notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov3_vitb16_pretrain.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 327M/327M [00:01<00:00, 289MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded states <class 'list'>\n",
      "test.csv columns: ['sample_id', 'image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm', 'target_name', 'target']\n",
      "                    sample_id              image_path Sampling_Date State  \\\n",
      "0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
      "1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
      "2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
      "\n",
      "           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n",
      "0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n",
      "1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n",
      "2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2751  \n",
      "rows (long): 1785 unique images: 357\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 0) CONFIG (edit these)\n",
    "# -------------------------\n",
    "import os, sys\n",
    "\n",
    "\n",
    "# Project code (must contain the csiro package)\n",
    "CSIRO_CODE_DIR = \"/notebooks/CSIRO\"\n",
    "\n",
    "# DINOv3 repo/code dir (must contain hubconf.py)\n",
    "DINO_REPO = \"/notebooks/dinov3\"\n",
    "\n",
    "# Ensemble checkpoints (.pt)\n",
    "WEIGHTS_PATHS = [\n",
    "    \"/notebooks/kaggle/csiro/output/v6_n_models2tiled_inpTrue_29d.pt\",\n",
    "]\n",
    "\n",
    "# Competition data\n",
    "COMP_ROOT = \"/notebooks/kaggle/csiro\"\n",
    "TEST_CSV = f\"{COMP_ROOT}/train.csv\"\n",
    "# IMPORTANT: test.csv image_path values look like \"test/IDxxxx.jpg\", so IMAGE_ROOT should be COMP_ROOT\n",
    "IMAGE_ROOT = COMP_ROOT\n",
    "SYMLINK = False\n",
    "# Inference params\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = os.cpu_count() - 3\n",
    "DEVICE = \"cuda\"  # or \"cpu\"\n",
    "\n",
    "# TTA / ensemble knobs\n",
    "TTA_N = 4\n",
    "TTA_BCS = 0.0\n",
    "TTA_HUE = 0.0\n",
    "TTA_AGG = \"mean\"\n",
    "INNER_AGG = \"mean\"\n",
    "OUTER_AGG = \"flatten\"  # aggregate over CV -> aggregate over seeds\n",
    "\n",
    "sub_id = \"2\"\n",
    "OUTPUT_PATH = f\"/notebooks/kaggle/csiro/sub/sub{sub_id}.csv\"\n",
    "WRITE_SUB = False\n",
    "\n",
    "sys.path.insert(0, \"/notebooks/CSIRO\")\n",
    "os.environ[\"COMET_API_KEY\"]=\"R7OuT6FolA02VmQRI82xDN48O\"\n",
    "os.environ[\"COMET_DISABLE_AUTO_LOGGING\"]=\"1\"\n",
    "os.environ[\"KAGGLE_API_TOKEN\"]=\"KGAT_4aac4afa024236c6a163b5e4af00b4c7\"\n",
    "os.environ[\"DINO_WB\"]=\"https://dinov3.llamameta.net/dinov3_vitb16/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "os.environ[\"DINO_WL\"]=\"https://dinov3.llamameta.net/dinov3_vitl16/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "os.environ[\"DINO_WL_plus\"]=\"https://dinov3.llamameta.net/dinov3_vith16plus/dinov3_vith16plus_pretrain_lvd1689m-7c1da9a5.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidW84aXJvdGQyeThwcGpuNXFveGthZTE4IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5NzI4MTd9fX1dfQ__&Signature=H5H5kLVc6V83i-s2euNHx6t9KlVeG27QKX6qtkXNiLwEzuCshJD4RfwUbQv8oBJOZXPezAVJZPRkYRdsb4jh-LQ72DZtEuNkjNKHf7Pn57wzee0bjEYjWdJmOqK4waaSe9TQqELM%7EPgzdAT4LCSHYcFQ%7EleRnHGGGJiHBmTd6e1xZYhvUCfkvVD1TG-zM7R0-P%7EMLetHMvWl%7EUapCMYthsWqZctsYAQKUQxsLrly8Y4EaM8hm5nowpArPZC4myNO1iiXld5Hc3t9CVLEdYT7LIct0x6cf3-B-6WOgxGb7LdLPCcZPPfoGgX3KGtTAgNQYOpGFs-hgILFHRKVOJ7T3A__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1893388161261111\"\n",
    "os.environ[\"DEFAULT_DINO_REPO_DIR\"]=\"/notebooks/dinov3\"\n",
    "os.environ[\"DEFAULT_DATA_ROOT\"]=\"/notebooks/kaggle/csiro\"\n",
    "os.environ[\"DINO_WEIGHTS_PATH\"] = DINO_WEIGHTS = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain.pth\"\n",
    "\n",
    "# --- Basic guards (set to None if unknown and fill later) ---\n",
    "for name, val in {\n",
    "    \"CSIRO_CODE_DIR\": CSIRO_CODE_DIR,\n",
    "    \"DINO_REPO\": DINO_REPO,\n",
    "    \"DINO_WEIGHTS\": DINO_WEIGHTS,\n",
    "    \"WEIGHTS_PATHS\": WEIGHTS_PATHS,\n",
    "    \"TEST_CSV\": TEST_CSV,\n",
    "    \"IMAGE_ROOT\": IMAGE_ROOT,\n",
    "}.items():\n",
    "    if val is None:\n",
    "        raise ValueError(f\"{name} is None; set it before running.\")\n",
    "\n",
    "sys.path.insert(0, CSIRO_CODE_DIR)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1) Imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import csiro\n",
    "from csiro.config import TARGETS, dino_hub_name, DEFAULT_MODEL_SIZE, DEFAULT_PLUS\n",
    "from csiro.data import TiledTTADataset\n",
    "from csiro.eval import predict_ensemble_tiled, load_ensemble_states\n",
    "print(\"TARGETS:\", TARGETS)\n",
    "\n",
    "if SYMLINK:\n",
    "    from pathlib import Path\n",
    "    # Create checkpoints dir\n",
    "    ckpt_dir = Path(torch.hub.get_dir()) / \"checkpoints\"\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Symlink the weight file from /kaggle/input (read-only) into the hub cache\n",
    "    src = Path(DINO_WEIGHTS)                  # /kaggle/input/.../dinov3_vitb16_pretrain.pth\n",
    "    dst = ckpt_dir / src.name                 # /kaggle/working/torch_hub/checkpoints/dinov3_vitb16_pretrain.pth\n",
    "\n",
    "    if not dst.exists():\n",
    "        dst.symlink_to(src)\n",
    "        \n",
    "# -------------------------\n",
    "# 2) Load checkpoint + backbone\n",
    "# -------------------------\n",
    "states = load_ensemble_states(WEIGHTS_PATHS)\n",
    "sys.path.insert(0, DINO_REPO)\n",
    "backbone = torch.hub.load(\n",
    "    DINO_REPO,\n",
    "    dino_hub_name(model_size=str(DEFAULT_MODEL_SIZE), plus=str(DEFAULT_PLUS)),\n",
    "    source=\"local\",\n",
    "    weights=os.environ[\"DINO_WEIGHTS_PATH\"],\n",
    ").cuda()\n",
    "backbone.eval()\n",
    "print(\"Loaded states\", type(states))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3) Read test.csv (long format)\n",
    "# -------------------------\n",
    "df = pd.read_csv(TEST_CSV)\n",
    "print(\"test.csv columns:\", list(df.columns))\n",
    "print(df.head(3))\n",
    "\n",
    "IMAGE_PATH_COL = \"image_path\"\n",
    "TARGET_NAME_COL = \"target_name\"\n",
    "SAMPLE_ID_COL = \"sample_id\"\n",
    "\n",
    "if IMAGE_PATH_COL not in df.columns:\n",
    "    raise ValueError(f\"Expected column {IMAGE_PATH_COL} in test.csv\")\n",
    "if TARGET_NAME_COL not in df.columns:\n",
    "    raise ValueError(f\"Expected column {TARGET_NAME_COL} in test.csv\")\n",
    "\n",
    "df_img = df.drop_duplicates(subset=[IMAGE_PATH_COL]).reset_index(drop=True)\n",
    "print(\"rows (long):\", len(df), \"unique images:\", len(df_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:05:06.209627Z",
     "iopub.status.busy": "2025-12-28T19:05:06.209273Z",
     "iopub.status.idle": "2025-12-28T19:05:12.694591Z",
     "shell.execute_reply": "2025-12-28T19:05:12.693554Z",
     "shell.execute_reply.started": "2025-12-28T19:05:06.209600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([3072, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m\n\u001b[1;32m     25\u001b[0m ds_base \u001b[38;5;241m=\u001b[39m TestDataset(df_img, IMAGE_ROOT, IMAGE_PATH_COL, IMG_SIZE)\n\u001b[1;32m     27\u001b[0m ds \u001b[38;5;241m=\u001b[39m TiledTTADataset(\n\u001b[1;32m     28\u001b[0m     ds_base,\n\u001b[1;32m     29\u001b[0m     tta_n\u001b[38;5;241m=\u001b[39mTTA_N,\n\u001b[1;32m     30\u001b[0m     bcs_val\u001b[38;5;241m=\u001b[39mTTA_BCS,\n\u001b[1;32m     31\u001b[0m     hue_val\u001b[38;5;241m=\u001b[39mTTA_HUE,\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_ensemble_tiled\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtta_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTTA_AGG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINNER_AGG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mouter_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTER_AGG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(preds\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:415\u001b[0m, in \u001b[0;36mpredict_ensemble_tiled\u001b[0;34m(data, states, backbone, batch_size, num_workers, device, backbone_dtype, trainable_dtype, tta_agg, inner_agg, outer_agg)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_agg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflatten\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    414\u001b[0m     flat_states \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m runs \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m run]\n\u001b[0;32m--> 415\u001b[0m     models \u001b[38;5;241m=\u001b[39m [_build_model_from_state(backbone, s, device, backbone_dtype) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m flat_states]\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _predict_with_models(models)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_agg \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:415\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_agg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflatten\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    414\u001b[0m     flat_states \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m runs \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m run]\n\u001b[0;32m--> 415\u001b[0m     models \u001b[38;5;241m=\u001b[39m [\u001b[43m_build_model_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackbone_dtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m flat_states]\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _predict_with_models(models)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_agg \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:140\u001b[0m, in \u001b[0;36m_build_model_from_state\u001b[0;34m(backbone, state, device, backbone_dtype)\u001b[0m\n\u001b[1;32m    138\u001b[0m         part \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m part \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m parts:\n\u001b[0;32m--> 140\u001b[0m             \u001b[43mpart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(state, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([3072, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 768])."
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 4) Dataset + inference\n",
    "# -------------------------\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, root, img_col, img_size):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = root\n",
    "        self.img_col = img_col\n",
    "        self.resize = T.Resize((int(img_size), int(img_size)), antialias=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        rel = self.df.loc[i, self.img_col]\n",
    "        p = os.path.join(self.root, rel) if self.root else rel\n",
    "        with Image.open(p) as im0:\n",
    "            im = im0.convert(\"RGB\")\n",
    "            left = im.crop((0, 0, 1000, 1000))\n",
    "            right = im.crop((1000, 0, 2000, 1000))\n",
    "        left = self.resize(left)\n",
    "        right = self.resize(right)\n",
    "        return left, right\n",
    "\n",
    "ds_base = TestDataset(df_img, IMAGE_ROOT, IMAGE_PATH_COL, IMG_SIZE)\n",
    "\n",
    "ds = TiledTTADataset(\n",
    "    ds_base,\n",
    "    tta_n=TTA_N,\n",
    "    bcs_val=TTA_BCS,\n",
    "    hue_val=TTA_HUE,\n",
    ")\n",
    "preds = predict_ensemble_tiled(\n",
    "    ds,\n",
    "    states=states,\n",
    "    backbone=backbone,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    device=DEVICE,\n",
    "    tta_agg=TTA_AGG,\n",
    "    inner_agg=INNER_AGG,\n",
    "    outer_agg=OUTER_AGG,\n",
    ")\n",
    "\n",
    "preds = preds.detach().cpu()\n",
    "print(\"preds shape:\", tuple(preds.shape))\n",
    "\n",
    "# -------------------------\n",
    "# 5) Build submission (long format)\n",
    "# -------------------------\n",
    "target_to_idx = {t: i for i, t in enumerate(TARGETS)}\n",
    "preds_np = preds.numpy()\n",
    "\n",
    "pred_by_path = {\n",
    "    df_img.loc[i, IMAGE_PATH_COL]: preds_np[i]\n",
    "    for i in range(len(df_img))\n",
    "}\n",
    "\n",
    "if SAMPLE_ID_COL in df.columns:\n",
    "    sample_ids = df[SAMPLE_ID_COL].astype(str)\n",
    "else:\n",
    "    image_ids = df[IMAGE_PATH_COL].apply(lambda p: os.path.splitext(os.path.basename(p))[0])\n",
    "    sample_ids = image_ids + \"__\" + df[TARGET_NAME_COL].astype(str)\n",
    "\n",
    "targets = []\n",
    "for i, row in df.iterrows():\n",
    "    p = row[IMAGE_PATH_COL]\n",
    "    t_name = row[TARGET_NAME_COL]\n",
    "    if t_name not in target_to_idx:\n",
    "        raise ValueError(f\"Unknown target_name: {t_name}\")\n",
    "    vec = pred_by_path[p]\n",
    "    targets.append(float(vec[target_to_idx[t_name]]))\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"sample_id\": sample_ids.values,\n",
    "    \"target\": np.asarray(targets, dtype=np.float32),\n",
    "})\n",
    "\n",
    "assert len(sub) == len(df)\n",
    "assert list(sub.columns) == [\"sample_id\", \"target\"]\n",
    "assert np.isfinite(sub[\"target\"].values).all()\n",
    "\n",
    "\n",
    "if WRITE_SUB:\n",
    "    sub.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(\"Wrote - \", OUTPUT_PATH)\n",
    "\n",
    "print(sub.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 9096612,
     "sourceId": 14256448,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9096715,
     "sourceId": 14256574,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9130324,
     "sourceId": 14302811,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9158539,
     "sourceId": 14343763,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 540735,
     "modelInstanceId": 533616,
     "sourceId": 703120,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 540735,
     "modelInstanceId": 526691,
     "sourceId": 694536,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 540735,
     "modelInstanceId": 533617,
     "sourceId": 703121,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 540735,
     "modelInstanceId": 533622,
     "sourceId": 703126,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "PyTorch 2.7.1 (cu118)",
   "language": "python",
   "name": "pt27cu118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
