{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ad570e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2237ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 0) CONFIG \n",
    "# -------------------------\n",
    "import os, sys\n",
    "\n",
    "# --- Env vars expected by csiro.config (no defaults) ---\n",
    "COMP_ROOT = \"/notebooks/kaggle/csiro\"\n",
    "TRAIN_CSV = f\"{COMP_ROOT}/train.csv\"\n",
    "TEST_CSV = f\"{COMP_ROOT}/test.csv\"\n",
    "\n",
    "IMAGE_ROOT = COMP_ROOT\n",
    "sub_id = \"3\"\n",
    "OUTPUT_PATH = f\"/notebooks/kaggle/csiro/sub/sub{sub_id}.csv\"\n",
    "BB_TEST = COPY_WEIGHTS = WRITE_SUB = False\n",
    "\n",
    "CSIRO_CODE_DIR = \"/notebooks/CSIRO\"\n",
    "DINO_REPO = CSIRO_CODE_DIR + \"/_dinov3\"\n",
    "sys.path.insert(0, CSIRO_CODE_DIR)\n",
    "sys.path.insert(0, DINO_REPO)\n",
    "\n",
    "os.environ[\"DEFAULT_DINO_ROOT\"] = DINO_REPO\n",
    "os.environ[\"DEFAULT_DATA_ROOT\"] = COMP_ROOT\n",
    "os.environ[\"DINO_B_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
    "os.environ[\"DINO_L_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) Imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import csiro\n",
    "from csiro.config import TARGETS, dino_hub_name\n",
    "from csiro.data import TiledSharedTTADataset, _maybe_preprocess_image\n",
    "from csiro.eval import predict_ensemble_tiled, load_ensemble_states\n",
    "\n",
    "# -------------------------\n",
    "# 1) Params\n",
    "# -------------------------\n",
    "WEIGHTS_PATHS = [\n",
    "    \"/notebooks/kaggle/csiro/output/states/CSIRO_v20_noPool_cv2_cv_state.pt\",\n",
    "]\n",
    "\n",
    "# Inference params\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = \"cuda\"  \n",
    "MODEL_SIZE = \"l\"\n",
    "DEFAULT_PLUS = \"\"\n",
    "IMG_PREPROCESS = True\n",
    "\n",
    "# TTA / ensemble knobs\n",
    "TTA_N = 3\n",
    "TTA_BCS = 0.1\n",
    "TTA_HUE = 0.1\n",
    "TTA_AGG = \"mean\"\n",
    "INNER_AGG = \"mean\"\n",
    "OUTER_AGG = \"flatten\"\n",
    "\n",
    "\n",
    "if MODEL_SIZE == \"b\":\n",
    "    DINO_WEIGHTS = os.getenv(\"DINO_B_WEIGHTS_PATH\")\n",
    "elif MODEL_SIZE == \"l\":\n",
    "    DINO_WEIGHTS = os.getenv(\"DINO_L_WEIGHTS_PATH\")\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "if COPY_WEIGHTS:\n",
    "    src = DINO_WEIGHTS\n",
    "    dst = f\"/kaggle/working/{os.path.basename(DINO_WEIGHTS)}\"\n",
    "    shutil.copyfile(src, dst)\n",
    "    DINO_WEIGHTS = dst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2c26f",
   "metadata": {},
   "source": [
    "# Review transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88324707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csiro.utils import preview_augments, build_color_jitter_sweep, load_train_dataset_simple\n",
    "_, dataset = load_train_dataset_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc30f5c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preview_augments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 3-point sweep around your default (0.25, 0.25, 0.25, 0.035)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tfms_list \u001b[38;5;241m=\u001b[39m build_color_jitter_sweep(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      6\u001b[0m     bcs_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.35\u001b[39m),\n\u001b[1;32m      7\u001b[0m     hue_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.035\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpreview_augments\u001b[49m(\n\u001b[1;32m     11\u001b[0m     tfms_list,\n\u001b[1;32m     12\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     13\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     14\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     15\u001b[0m     show_titles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preview_augments' is not defined"
     ]
    }
   ],
   "source": [
    "from csiro.utils import build_color_jitter_sweep\n",
    "\n",
    "# 3-point sweep around your default (0.25, 0.25, 0.25, 0.035)\n",
    "tfms_list = build_color_jitter_sweep(\n",
    "    3,\n",
    "    bcs_range=(0.2, 0.35),\n",
    "    hue_range=(0.035, 0.1),\n",
    ")\n",
    "\n",
    "preview_augments(\n",
    "    tfms_list,\n",
    "    dataset=dataset[1],\n",
    "    k=3,\n",
    "    seed=0,\n",
    "    show_titles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22240e",
   "metadata": {},
   "source": [
    "# Eval review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "if BB_TEST:\n",
    "    backbone = torch.hub.load(\n",
    "        DINO_REPO,\n",
    "        dino_hub_name(model_size=MODEL_SIZE, plus=str(DEFAULT_PLUS)),\n",
    "        source=\"local\",\n",
    "        weights=DINO_WEIGHTS,\n",
    "    ).cuda()\n",
    "\n",
    "    backbone.rope_embed.rescale_coords = None\n",
    "\n",
    "    for i in range(len(backbone.blocks)):\n",
    "        assert backbone.blocks[i].sample_drop_ratio == 0\n",
    "        \n",
    "    for n, p in backbone.named_modules():\n",
    "        if \"drop\" in n:\n",
    "            assert float(p.p) == 0-0\n",
    "\n",
    "    inp = torch.randn(1, 3, 512, 512).cuda()\n",
    "    \n",
    "    backbone.train()\n",
    "    with torch.no_grad():\n",
    "        x1 = backbone(inp)[0]\n",
    "        x2 = backbone(inp)[0]\n",
    "        \n",
    "    print(torch.allclose(x1[\"x_postnorm\"], x2[\"x_postnorm\"]))\n",
    "        \n",
    "    backbone.eval()\n",
    "    with torch.no_grad():\n",
    "        x1 = backbone(inp)[0]\n",
    "        x2 = backbone(inp)[0]\n",
    "        \n",
    "    print(torch.allclose(x1[\"x_postnorm\"], x2[\"x_postnorm\"]))\n",
    "    assert not BB_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6168804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Load checkpoint + backbone\n",
    "# -------------------------\n",
    "states = load_ensemble_states(WEIGHTS_PATHS)\n",
    "backbone = torch.hub.load(\n",
    "    DINO_REPO,\n",
    "    dino_hub_name(model_size=MODEL_SIZE, plus=str(DEFAULT_PLUS)),\n",
    "    source=\"local\",\n",
    "    weights=DINO_WEIGHTS,\n",
    ").cuda()\n",
    "backbone.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 3) Read train.csv (wide_df)\n",
    "# -------------------------\n",
    "from csiro.data import load_train_wide\n",
    "\n",
    "wide_df = load_train_wide(TRAIN_CSV, root=COMP_ROOT)\n",
    "IMAGE_PATH_COL = \"image_path\"\n",
    "TARGET_NAME_COL = \"target_name\"\n",
    "SAMPLE_ID_COL = \"sample_id\"\n",
    "\n",
    "# Build long df view for convenience (same shape as raw train.csv)\n",
    "df = wide_df.copy()\n",
    "\n",
    "\n",
    "#df_img = df.drop_duplicates(subset=[IMAGE_PATH_COL]).reset_index(drop=True)\n",
    "#print(\"rows_long:\", len(df), \"unique_images:\", len(df_img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac561b29",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b78862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Dataset + inference\n",
    "# -------------------------\n",
    "from csiro.data import BiomassFullCached, TiledSharedTransformView\n",
    "\n",
    "# Labeled base dataset (returns PIL + y)\n",
    "ds_base = BiomassFullCached(\n",
    "    wide_df,\n",
    "    cache_images=False,\n",
    "    img_preprocess=IMG_PREPROCESS,\n",
    ")\n",
    "\n",
    "# Deterministic eval view (no TTA dimension)\n",
    "ds = TiledSharedTransformView(\n",
    "    ds_base,\n",
    "    geom_tfms=None,\n",
    "    img_size=IMG_SIZE,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d944db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_path =\"/notebooks/kaggle/csiro/output/states/CSIRO_v20_noPool_cv2_cv_state.pt\"\n",
    "import torch\n",
    "\n",
    "state = torch.load(sd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "080e44ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7200520634651184, 0.743245542049408, 0.7522132992744446],\n",
       " [0.7776366472244263, 0.7613773941993713, 0.7739927768707275],\n",
       " [0.8398525714874268, 0.8388647437095642, 0.7700711488723755]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"fold_model_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20567eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_idx': 0, 'fold_idx': 0, 'n_models': 3, 'per_model_scores': [0.7149139642715454, 0.7243577241897583, 0.7579962015151978], 'ensemble_score': 0.7448190450668335}]\n",
      "[{'run_idx': 0, 'fold_idx': 1, 'n_models': 3, 'per_model_scores': [0.7398039102554321, 0.7267219424247742, 0.7379381656646729], 'ensemble_score': 0.7519531846046448}]\n",
      "[{'run_idx': 0, 'fold_idx': 2, 'n_models': 3, 'per_model_scores': [0.8208684921264648, 0.8365305662155151, 0.7871720194816589], 'ensemble_score': 0.8433529734611511}]\n",
      "Missing fold 3 in checkpoint states.\n",
      "Missing fold 4 in checkpoint states.\n",
      "Fold 5 not found in CV iterator.\n"
     ]
    }
   ],
   "source": [
    "# Eval: replay fold ensemble score\n",
    "from csiro.eval import eval_fold_ensemble_from_pt\n",
    "\n",
    "pt_path = \"/notebooks/kaggle/csiro/output/states/CSIRO_v20_noPool_cv2_cv_state.pt\"\n",
    "for i in range(6):\n",
    "    # Example usage\n",
    "    try:\n",
    "        results = eval_fold_ensemble_from_pt(\n",
    "            pt_path=pt_path,\n",
    "            fold_idx=i,\n",
    "            dataset=ds,\n",
    "            backbone=backbone,\n",
    "            wide_df=df,\n",
    "            cv_cfg=2,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            inner_agg=INNER_AGG,\n",
    "            tta_agg=TTA_AGG,\n",
    "        )\n",
    "        print(results)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.7.1 (cu118)",
   "language": "python",
   "name": "pt27cu118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
