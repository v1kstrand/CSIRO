{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ad570e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2237ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 0) CONFIG \n",
    "# -------------------------\n",
    "import os, sys\n",
    "\n",
    "# --- Env vars expected by csiro.config (no defaults) ---\n",
    "COMP_ROOT = \"/notebooks/kaggle/csiro\"\n",
    "TRAIN_CSV = f\"{COMP_ROOT}/train.csv\"\n",
    "TEST_CSV = f\"{COMP_ROOT}/test.csv\"\n",
    "\n",
    "IMAGE_ROOT = COMP_ROOT\n",
    "sub_id = \"3\"\n",
    "OUTPUT_PATH = f\"/notebooks/kaggle/csiro/sub/sub{sub_id}.csv\"\n",
    "BB_TEST = COPY_WEIGHTS = WRITE_SUB = False\n",
    "\n",
    "CSIRO_CODE_DIR = \"/notebooks/CSIRO\"\n",
    "DINO_REPO = CSIRO_CODE_DIR + \"/_dinov3\"\n",
    "sys.path.insert(0, CSIRO_CODE_DIR)\n",
    "sys.path.insert(0, DINO_REPO)\n",
    "\n",
    "os.environ[\"DEFAULT_DINO_ROOT\"] = DINO_REPO\n",
    "os.environ[\"DEFAULT_DATA_ROOT\"] = COMP_ROOT\n",
    "os.environ[\"DINO_B_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
    "os.environ[\"DINO_L_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) Imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import csiro\n",
    "from csiro.config import TARGETS, dino_hub_name\n",
    "from csiro.data import TiledSharedTTADataset, _maybe_preprocess_image\n",
    "from csiro.eval import predict_ensemble_tiled, load_ensemble_states\n",
    "\n",
    "# -------------------------\n",
    "# 1) Params\n",
    "# -------------------------\n",
    "WEIGHTS_PATHS = [\n",
    "    \"/notebooks/kaggle/csiro/output/states/CSIRO_v20_rectMixUp3_cv_state.pt\",\n",
    "]\n",
    "\n",
    "# Inference params\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = \"cuda\"  \n",
    "MODEL_SIZE = \"l\"\n",
    "DEFAULT_PLUS = \"\"\n",
    "IMG_PREPROCESS = True\n",
    "\n",
    "# TTA / ensemble knobs\n",
    "TTA_N = 3\n",
    "TTA_BCS = 0.1\n",
    "TTA_HUE = 0.1\n",
    "TTA_AGG = \"mean\"\n",
    "INNER_AGG = \"mean\"\n",
    "OUTER_AGG = \"flatten\"\n",
    "\n",
    "\n",
    "if MODEL_SIZE == \"b\":\n",
    "    DINO_WEIGHTS = os.getenv(\"DINO_B_WEIGHTS_PATH\")\n",
    "elif MODEL_SIZE == \"l\":\n",
    "    DINO_WEIGHTS = os.getenv(\"DINO_L_WEIGHTS_PATH\")\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "if COPY_WEIGHTS:\n",
    "    src = DINO_WEIGHTS\n",
    "    dst = f\"/kaggle/working/{os.path.basename(DINO_WEIGHTS)}\"\n",
    "    shutil.copyfile(src, dst)\n",
    "    DINO_WEIGHTS = dst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2c26f",
   "metadata": {},
   "source": [
    "# Review transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88324707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csiro.utils import preview_augments, build_color_jitter_sweep, load_train_dataset_simple\n",
    "_, dataset = load_train_dataset_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc30f5c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preview_augments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 3-point sweep around your default (0.25, 0.25, 0.25, 0.035)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tfms_list \u001b[38;5;241m=\u001b[39m build_color_jitter_sweep(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      6\u001b[0m     bcs_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.35\u001b[39m),\n\u001b[1;32m      7\u001b[0m     hue_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.035\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpreview_augments\u001b[49m(\n\u001b[1;32m     11\u001b[0m     tfms_list,\n\u001b[1;32m     12\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     13\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     14\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     15\u001b[0m     show_titles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preview_augments' is not defined"
     ]
    }
   ],
   "source": [
    "from csiro.utils import build_color_jitter_sweep\n",
    "\n",
    "# 3-point sweep around your default (0.25, 0.25, 0.25, 0.035)\n",
    "tfms_list = build_color_jitter_sweep(\n",
    "    3,\n",
    "    bcs_range=(0.2, 0.35),\n",
    "    hue_range=(0.035, 0.1),\n",
    ")\n",
    "\n",
    "preview_augments(\n",
    "    tfms_list,\n",
    "    dataset=dataset[1],\n",
    "    k=3,\n",
    "    seed=0,\n",
    "    show_titles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22240e",
   "metadata": {},
   "source": [
    "# Eval review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "if BB_TEST:\n",
    "    backbone = torch.hub.load(\n",
    "        DINO_REPO,\n",
    "        dino_hub_name(model_size=MODEL_SIZE, plus=str(DEFAULT_PLUS)),\n",
    "        source=\"local\",\n",
    "        weights=DINO_WEIGHTS,\n",
    "    ).cuda()\n",
    "\n",
    "    backbone.rope_embed.rescale_coords = None\n",
    "\n",
    "    for i in range(len(backbone.blocks)):\n",
    "        assert backbone.blocks[i].sample_drop_ratio == 0\n",
    "        \n",
    "    for n, p in backbone.named_modules():\n",
    "        if \"drop\" in n:\n",
    "            assert float(p.p) == 0-0\n",
    "\n",
    "    inp = torch.randn(1, 3, 512, 512).cuda()\n",
    "    \n",
    "    backbone.train()\n",
    "    with torch.no_grad():\n",
    "        x1 = backbone(inp)[0]\n",
    "        x2 = backbone(inp)[0]\n",
    "        \n",
    "    print(torch.allclose(x1[\"x_postnorm\"], x2[\"x_postnorm\"]))\n",
    "        \n",
    "    backbone.eval()\n",
    "    with torch.no_grad():\n",
    "        x1 = backbone(inp)[0]\n",
    "        x2 = backbone(inp)[0]\n",
    "        \n",
    "    print(torch.allclose(x1[\"x_postnorm\"], x2[\"x_postnorm\"]))\n",
    "    assert not BB_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6168804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Load checkpoint + backbone\n",
    "# -------------------------\n",
    "states = load_ensemble_states(WEIGHTS_PATHS)\n",
    "backbone = torch.hub.load(\n",
    "    DINO_REPO,\n",
    "    dino_hub_name(model_size=MODEL_SIZE, plus=str(DEFAULT_PLUS)),\n",
    "    source=\"local\",\n",
    "    weights=DINO_WEIGHTS,\n",
    ").cuda()\n",
    "backbone.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 3) Read train.csv (wide_df)\n",
    "# -------------------------\n",
    "from csiro.data import load_train_wide\n",
    "\n",
    "wide_df = load_train_wide(TRAIN_CSV, root=COMP_ROOT)\n",
    "IMAGE_PATH_COL = \"image_path\"\n",
    "TARGET_NAME_COL = \"target_name\"\n",
    "SAMPLE_ID_COL = \"sample_id\"\n",
    "\n",
    "# Build long df view for convenience (same shape as raw train.csv)\n",
    "df = wide_df.copy()\n",
    "\n",
    "\n",
    "#df_img = df.drop_duplicates(subset=[IMAGE_PATH_COL]).reset_index(drop=True)\n",
    "#print(\"rows_long:\", len(df), \"unique_images:\", len(df_img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac561b29",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b78862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Dataset + inference\n",
    "# -------------------------\n",
    "from csiro.data import BiomassFullCached, TiledSharedTransformView\n",
    "\n",
    "# Labeled base dataset (returns PIL + y)\n",
    "ds_base = BiomassFullCached(\n",
    "    wide_df,\n",
    "    cache_images=False,\n",
    "    img_preprocess=IMG_PREPROCESS,\n",
    ")\n",
    "\n",
    "# Deterministic eval view (no TTA dimension)\n",
    "ds = TiledSharedTransformView(\n",
    "    ds_base,\n",
    "    geom_tfms=None,\n",
    "    img_size=IMG_SIZE,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20567eaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/notebooks/kaggle/csiro/output/states/CSIRO_v20_mixUp3_cv_state.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m pt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/notebooks/kaggle/csiro/output/states/CSIRO_v20_mixUp3_cv_state.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43meval_fold_ensemble_from_pt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwide_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINNER_AGG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtta_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTTA_AGG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m results\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:414\u001b[0m, in \u001b[0;36meval_fold_ensemble_from_pt\u001b[0;34m(pt_path, fold_idx, dataset, backbone, wide_df, va_idx, cv_cfg, batch_size, num_workers, device, backbone_dtype, trainable_dtype, tta_agg, inner_agg, k_weights, tiled_inp)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval_fold_ensemble_from_pt\u001b[39m(\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    397\u001b[0m     pt_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m     tiled_inp: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    413\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m--> 414\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[43mload_states_from_pt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     runs \u001b[38;5;241m=\u001b[39m _normalize_runs(states)\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runs:\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:254\u001b[0m, in \u001b[0;36mload_states_from_pt\u001b[0;34m(pt_path)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_states_from_pt\u001b[39m(pt_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 254\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ckpt, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ckpt \u001b[38;5;28;01melse\u001b[39;00m ckpt\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/notebooks/kaggle/csiro/output/states/CSIRO_v20_mixUp3_cv_state.pt'"
     ]
    }
   ],
   "source": [
    "# Eval: replay fold ensemble score\n",
    "from csiro.eval import eval_fold_ensemble_from_pt\n",
    "\n",
    "pt_path = \"/notebooks/kaggle/csiro/output/states/CSIRO_v20_mixUp3_cv_state.pt\"\n",
    "# Example usage\n",
    "results = eval_fold_ensemble_from_pt(\n",
    "    pt_path=pt_path,\n",
    "    fold_idx=3,\n",
    "    dataset=ds,\n",
    "    backbone=backbone,\n",
    "    wide_df=df,\n",
    "    cv_cfg=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    inner_agg=INNER_AGG,\n",
    "    tta_agg=TTA_AGG,\n",
    ")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b683578",
   "metadata": {},
   "outputs": [],
   "source": [
    "/notebooks/kaggle/csiro/output/states/CSIRO_v20_rectMixUp3_cv_state.pt\n",
    "/notebooks/kaggle/csiro/output/states/CSIRO_v20_mixUp3_cv_state.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.7.1 (cu118)",
   "language": "python",
   "name": "pt27cu118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
