{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ad570e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2237ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 0) CONFIG \n",
    "# -------------------------\n",
    "import os, sys\n",
    "\n",
    "# --- Env vars expected by csiro.config (no defaults) ---\n",
    "COMP_ROOT = \"/notebooks/kaggle/csiro\"\n",
    "TRAIN_CSV = f\"{COMP_ROOT}/train.csv\"\n",
    "TEST_CSV = f\"{COMP_ROOT}/test.csv\"\n",
    "\n",
    "IMAGE_ROOT = COMP_ROOT\n",
    "sub_id = \"3\"\n",
    "OUTPUT_PATH = f\"/notebooks/kaggle/csiro/sub/sub{sub_id}.csv\"\n",
    "BB_TEST = COPY_WEIGHTS = WRITE_SUB = False\n",
    "\n",
    "CSIRO_CODE_DIR = \"/notebooks/CSIRO\"\n",
    "DINO_REPO = CSIRO_CODE_DIR + \"/_dinov3\"\n",
    "sys.path.insert(0, CSIRO_CODE_DIR)\n",
    "sys.path.insert(0, DINO_REPO)\n",
    "\n",
    "os.environ[\"DEFAULT_DINO_ROOT\"] = DINO_REPO\n",
    "os.environ[\"DEFAULT_DATA_ROOT\"] = COMP_ROOT\n",
    "os.environ[\"DINO_B_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
    "os.environ[\"DINO_L_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) Imports\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import csiro\n",
    "from csiro.config import TARGETS, dino_hub_name\n",
    "from csiro.data import TiledSharedTTADataset, _maybe_preprocess_image\n",
    "from csiro.eval import predict_ensemble_tiled, load_ensemble_states\n",
    "\n",
    "# -------------------------\n",
    "# 1) Params\n",
    "# -------------------------\n",
    "WEIGHTS_PATHS = [\n",
    "    \"/notebooks/kaggle/csiro/output/states/CSIRO_v20_rectMixUp3_cv_state.pt\",\n",
    "]\n",
    "\n",
    "# Inference params\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = \"cuda\"  \n",
    "MODEL_SIZE = \"l\"\n",
    "DEFAULT_PLUS = \"\"\n",
    "IMG_PREPROCESS = True\n",
    "\n",
    "# TTA / ensemble knobs\n",
    "TTA_N = 3\n",
    "TTA_BCS = 0.1\n",
    "TTA_HUE = 0.1\n",
    "TTA_AGG = \"mean\"\n",
    "INNER_AGG = \"mean\"\n",
    "OUTER_AGG = \"flatten\"\n",
    "\n",
    "\n",
    "if MODEL_SIZE == \"b\":\n",
    "    DINO_WEIGHTS = os.getenv(\"DINO_B_WEIGHTS_PATH\")\n",
    "elif MODEL_SIZE == \"l\":\n",
    "    DINO_WEIGHTS = os.getenv(\"DINO_L_WEIGHTS_PATH\")\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "if COPY_WEIGHTS:\n",
    "    src = DINO_WEIGHTS\n",
    "    dst = f\"/kaggle/working/{os.path.basename(DINO_WEIGHTS)}\"\n",
    "    shutil.copyfile(src, dst)\n",
    "    DINO_WEIGHTS = dst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2c26f",
   "metadata": {},
   "source": [
    "# Review transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88324707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csiro.utils import preview_augments, build_color_jitter_sweep, load_train_dataset_simple\n",
    "_, dataset = load_train_dataset_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc30f5c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preview_augments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 3-point sweep around your default (0.25, 0.25, 0.25, 0.035)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tfms_list \u001b[38;5;241m=\u001b[39m build_color_jitter_sweep(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      6\u001b[0m     bcs_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.35\u001b[39m),\n\u001b[1;32m      7\u001b[0m     hue_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.035\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpreview_augments\u001b[49m(\n\u001b[1;32m     11\u001b[0m     tfms_list,\n\u001b[1;32m     12\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     13\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     14\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     15\u001b[0m     show_titles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preview_augments' is not defined"
     ]
    }
   ],
   "source": [
    "from csiro.utils import build_color_jitter_sweep\n",
    "\n",
    "# 3-point sweep around your default (0.25, 0.25, 0.25, 0.035)\n",
    "tfms_list = build_color_jitter_sweep(\n",
    "    3,\n",
    "    bcs_range=(0.2, 0.35),\n",
    "    hue_range=(0.035, 0.1),\n",
    ")\n",
    "\n",
    "preview_augments(\n",
    "    tfms_list,\n",
    "    dataset=dataset[1],\n",
    "    k=3,\n",
    "    seed=0,\n",
    "    show_titles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22240e",
   "metadata": {},
   "source": [
    "# Eval review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "if BB_TEST:\n",
    "    backbone = torch.hub.load(\n",
    "        DINO_REPO,\n",
    "        dino_hub_name(model_size=MODEL_SIZE, plus=str(DEFAULT_PLUS)),\n",
    "        source=\"local\",\n",
    "        weights=DINO_WEIGHTS,\n",
    "    ).cuda()\n",
    "\n",
    "    backbone.rope_embed.rescale_coords = None\n",
    "\n",
    "    for i in range(len(backbone.blocks)):\n",
    "        assert backbone.blocks[i].sample_drop_ratio == 0\n",
    "        \n",
    "    for n, p in backbone.named_modules():\n",
    "        if \"drop\" in n:\n",
    "            assert float(p.p) == 0-0\n",
    "\n",
    "    inp = torch.randn(1, 3, 512, 512).cuda()\n",
    "    \n",
    "    backbone.train()\n",
    "    with torch.no_grad():\n",
    "        x1 = backbone(inp)[0]\n",
    "        x2 = backbone(inp)[0]\n",
    "        \n",
    "    print(torch.allclose(x1[\"x_postnorm\"], x2[\"x_postnorm\"]))\n",
    "        \n",
    "    backbone.eval()\n",
    "    with torch.no_grad():\n",
    "        x1 = backbone(inp)[0]\n",
    "        x2 = backbone(inp)[0]\n",
    "        \n",
    "    print(torch.allclose(x1[\"x_postnorm\"], x2[\"x_postnorm\"]))\n",
    "    assert not BB_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6168804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Load checkpoint + backbone\n",
    "# -------------------------\n",
    "states = load_ensemble_states(WEIGHTS_PATHS)\n",
    "backbone = torch.hub.load(\n",
    "    DINO_REPO,\n",
    "    dino_hub_name(model_size=MODEL_SIZE, plus=str(DEFAULT_PLUS)),\n",
    "    source=\"local\",\n",
    "    weights=DINO_WEIGHTS,\n",
    ").cuda()\n",
    "backbone.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 3) Read train.csv (wide_df)\n",
    "# -------------------------\n",
    "from csiro.data import load_train_wide\n",
    "\n",
    "wide_df = load_train_wide(TRAIN_CSV, root=COMP_ROOT)\n",
    "IMAGE_PATH_COL = \"image_path\"\n",
    "TARGET_NAME_COL = \"target_name\"\n",
    "SAMPLE_ID_COL = \"sample_id\"\n",
    "\n",
    "# Build long df view for convenience (same shape as raw train.csv)\n",
    "df = wide_df.copy()\n",
    "\n",
    "\n",
    "#df_img = df.drop_duplicates(subset=[IMAGE_PATH_COL]).reset_index(drop=True)\n",
    "#print(\"rows_long:\", len(df), \"unique_images:\", len(df_img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac561b29",
   "metadata": {},
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b78862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Dataset + inference\n",
    "# -------------------------\n",
    "from csiro.data import BiomassFullCached, TiledSharedTransformView\n",
    "\n",
    "# Labeled base dataset (returns PIL + y)\n",
    "ds_base = BiomassFullCached(\n",
    "    wide_df,\n",
    "    cache_images=False,\n",
    "    img_preprocess=IMG_PREPROCESS,\n",
    ")\n",
    "\n",
    "# Deterministic eval view (no TTA dimension)\n",
    "ds = TiledSharedTransformView(\n",
    "    ds_base,\n",
    "    geom_tfms=None,\n",
    "    img_size=IMG_SIZE,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20567eaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input [B,C,H,W], got (16, 2, 3, 512, 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m pt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/notebooks/kaggle/csiro/output/states/CSIRO_v20_rectMixUp3_cv_state.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43meval_fold_ensemble_from_pt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwide_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINNER_AGG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtta_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTTA_AGG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m results\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:523\u001b[0m, in \u001b[0;36meval_fold_ensemble_from_pt\u001b[0;34m(pt_path, fold_idx, dataset, backbone, wide_df, va_idx, cv_cfg, batch_size, num_workers, device, backbone_dtype, trainable_dtype, tta_agg, inner_agg, k_weights, tiled_inp)\u001b[0m\n\u001b[1;32m    521\u001b[0m     fold_states \u001b[38;5;241m=\u001b[39m [_resolve_kweights_state(s, \u001b[38;5;28mint\u001b[39m(k_weights)) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m fold_states]\n\u001b[1;32m    522\u001b[0m models \u001b[38;5;241m=\u001b[39m [_build_model_from_state(backbone, s, device, backbone_dtype) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m fold_states]\n\u001b[0;32m--> 523\u001b[0m per_model_scores \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(eval_global_wr2(m, dl, w_vec, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[1;32m    524\u001b[0m ens_score \u001b[38;5;241m=\u001b[39m _eval_ensemble(models)\n\u001b[1;32m    525\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    527\u001b[0m         run_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(run_idx),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    533\u001b[0m )\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:523\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    521\u001b[0m     fold_states \u001b[38;5;241m=\u001b[39m [_resolve_kweights_state(s, \u001b[38;5;28mint\u001b[39m(k_weights)) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m fold_states]\n\u001b[1;32m    522\u001b[0m models \u001b[38;5;241m=\u001b[39m [_build_model_from_state(backbone, s, device, backbone_dtype) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m fold_states]\n\u001b[0;32m--> 523\u001b[0m per_model_scores \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(\u001b[43meval_global_wr2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[1;32m    524\u001b[0m ens_score \u001b[38;5;241m=\u001b[39m _eval_ensemble(models)\n\u001b[1;32m    525\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    527\u001b[0m         run_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(run_idx),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    533\u001b[0m )\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/metrics.py:20\u001b[0m, in \u001b[0;36meval_global_wr2\u001b[0;34m(model, dl_va, w_vec, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m y_log \u001b[38;5;241m=\u001b[39m y_log\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m p_raw \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     21\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexpm1(y_log\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     22\u001b[0m pred_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_space\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/model.py:741\u001b[0m, in \u001b[0;36mFullDINOv3RegressorRect3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 741\u001b[0m     feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m     green, clover, dead \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_components(feats)\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compose_outputs(green, clover, dead)\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/model.py:704\u001b[0m, in \u001b[0;36mFullDINOv3RegressorRect3._encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input [B,C,H,W], got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mrope_embed\u001b[38;5;241m.\u001b[39mrescale_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone_grad):\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input [B,C,H,W], got (16, 2, 3, 512, 512)"
     ]
    }
   ],
   "source": [
    "# Eval: replay fold ensemble score\n",
    "from csiro.eval import eval_fold_ensemble_from_pt\n",
    "\n",
    "pt_path = \"/notebooks/kaggle/csiro/output/states/CSIRO_v20_rectMixUp3_cv_state.pt\"\n",
    "# Example usage\n",
    "results = eval_fold_ensemble_from_pt(\n",
    "    pt_path=pt_path,\n",
    "    fold_idx=3,\n",
    "    dataset=ds,\n",
    "    backbone=backbone,\n",
    "    wide_df=df,\n",
    "    cv_cfg=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    inner_agg=INNER_AGG,\n",
    "    tta_agg=TTA_AGG,\n",
    ")\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.7.1 (cu118)",
   "language": "python",
   "name": "pt27cu118"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
