{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd84072",
   "metadata": {},
   "source": [
    "# CSIRO OOF Prediction EDA (tiled)\n",
    "This notebook builds OOF predictions using a saved checkpoint and a recreated CV split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbec7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 0) CONFIG (edit these)\n",
    "# -------------------------\n",
    "import os, sys\n",
    "\n",
    "CSIRO_CODE_DIR = \"/notebooks/CSIRO\"\n",
    "DINO_REPO = \"/notebooks/dinov3\"\n",
    "DINO_WEIGHTS = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain.pth\"\n",
    "PT_PATH = \"/notebooks/kaggle/csiro/output/v7_tile_swapTruetiled_inpTruen_models2_e15.pt\"\n",
    "\n",
    "DATA_ROOT = \"/notebooks/kaggle/csiro\"\n",
    "TRAIN_CSV = f\"{DATA_ROOT}/train.csv\"\n",
    "\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = max(0, (os.cpu_count() or 0) - 2)\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "CV_PARAMS = dict(mode=\"gkf\", cv_seed=126015, n_splits=5)\n",
    "\n",
    "OUT_PATH = \"/notebooks/kaggle/csiro/oof/oof_preds.csv\"\n",
    "\n",
    "# Guard rails\n",
    "for name, val in {\n",
    "    \"CSIRO_CODE_DIR\": CSIRO_CODE_DIR,\n",
    "    \"DINO_REPO\": DINO_REPO,\n",
    "    \"DINO_WEIGHTS\": DINO_WEIGHTS,\n",
    "    \"PT_PATH\": PT_PATH,\n",
    "    \"TRAIN_CSV\": TRAIN_CSV,\n",
    "}.items():\n",
    "    if val is None:\n",
    "        raise ValueError(f\"{name} is None; set it before running.\")\n",
    "\n",
    "sys.path.insert(0, CSIRO_CODE_DIR)\n",
    "sys.path.insert(0, DINO_REPO)\n",
    "os.environ[\"DINO_WEIGHTS_PATH\"] = DINO_WEIGHTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4936b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1) Imports\n",
    "# -------------------------\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from csiro.config import TARGETS, DEFAULT_MODEL_SIZE, DEFAULT_PLUS, dino_hub_name\n",
    "from csiro.data import BiomassTiledCached, load_train_wide\n",
    "from csiro.utils_v2 import make_oof_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96972c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows 357 targets ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 2) Load data + backbone\n",
    "# -------------------------\n",
    "wide_df = load_train_wide(TRAIN_CSV, root=DATA_ROOT)\n",
    "dataset = BiomassTiledCached(wide_df, img_size=IMG_SIZE)\n",
    "\n",
    "backbone = torch.hub.load(\n",
    "    DINO_REPO,\n",
    "    dino_hub_name(model_size=str(DEFAULT_MODEL_SIZE), plus=str(DEFAULT_PLUS)),\n",
    "    source=\"local\",\n",
    "    weights=DINO_WEIGHTS,\n",
    ").to(DEVICE)\n",
    "backbone.eval()\n",
    "\n",
    "print(\"rows\", len(wide_df), \"targets\", TARGETS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f33469",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 3) Build OOF predictions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m oof \u001b[38;5;241m=\u001b[39m \u001b[43mmake_oof_predictions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwide_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwide_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpt_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mPT_PATH\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCV_PARAMS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mouter_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m preds \u001b[38;5;241m=\u001b[39m oof[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     18\u001b[0m fold_id \u001b[38;5;241m=\u001b[39m oof[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/utils_v2.py:140\u001b[0m, in \u001b[0;36mmake_oof_predictions\u001b[0;34m(dataset, wide_df, backbone, states, pt_paths, cv_params, batch_size, num_workers, device, tta_agg, inner_agg, outer_agg, tiled_inp)\u001b[0m\n\u001b[1;32m    137\u001b[0m subset \u001b[38;5;241m=\u001b[39m Subset(dataset, va_idx)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tiled_inp:\n\u001b[0;32m--> 140\u001b[0m     preds_f \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_ensemble_tiled\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruns_f\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtta_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtta_agg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_agg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mouter_agg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_agg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     preds_f \u001b[38;5;241m=\u001b[39m predict_ensemble(\n\u001b[1;32m    153\u001b[0m         subset,\n\u001b[1;32m    154\u001b[0m         states\u001b[38;5;241m=\u001b[39mruns_f,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         outer_agg\u001b[38;5;241m=\u001b[39mouter_agg,\n\u001b[1;32m    162\u001b[0m     )\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:423\u001b[0m, in \u001b[0;36mpredict_ensemble_tiled\u001b[0;34m(data, states, backbone, batch_size, num_workers, device, backbone_dtype, trainable_dtype, tta_agg, inner_agg, outer_agg)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m runs:\n\u001b[1;32m    422\u001b[0m         models \u001b[38;5;241m=\u001b[39m [_build_model_from_state(backbone, s, device, backbone_dtype) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m run]\n\u001b[0;32m--> 423\u001b[0m         preds_runs\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_predict_with_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _agg_stack(preds_runs, outer_agg)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown outer_agg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mouter_agg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/CSIRO/csiro/eval.py:382\u001b[0m, in \u001b[0;36mpredict_ensemble_tiled.<locals>._predict_with_models\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m    380\u001b[0m preds: \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode(), autocast_context(device, dtype\u001b[38;5;241m=\u001b[39mtrainable_dtype):\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    384\u001b[0m             x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1515\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1513\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(idx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1550\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1550\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/_utils.py:750\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/notebooks/venvs/pt27cu118/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 240, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 3) Build OOF predictions\n",
    "# -------------------------\n",
    "oof = make_oof_predictions(\n",
    "    dataset=dataset,\n",
    "    wide_df=wide_df,\n",
    "    backbone=backbone,\n",
    "    pt_paths=[PT_PATH],\n",
    "    cv_params=CV_PARAMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    device=DEVICE,\n",
    "    inner_agg=\"mean\",\n",
    "    outer_agg=\"mean\",\n",
    ")\n",
    "\n",
    "preds = oof[\"preds\"].numpy()\n",
    "fold_id = oof[\"fold_id\"]\n",
    "print(\"preds shape\", preds.shape, \"folds\", pd.Series(fold_id).nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Assemble OOF table\n",
    "# -------------------------\n",
    "df_out = wide_df.copy()\n",
    "df_out[\"fold_id\"] = fold_id\n",
    "for i, t in enumerate(TARGETS):\n",
    "    df_out[f\"{t}_pred\"] = preds[:, i]\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "df_out.to_csv(OUT_PATH, index=False)\n",
    "print(\"Wrote\", OUT_PATH)\n",
    "df_out.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.7.1 (cu118)",
   "language": "python",
   "name": "pt27cu118"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
