{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2ae06b90",
      "metadata": {},
      "source": [
        "# TTT Sweep: Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "68e40d79",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "CSIRO_CODE_DIR = \"/notebooks/CSIRO\"\n",
        "sys.path.insert(0, CSIRO_CODE_DIR)\n",
        "os.environ[\"DEFAULT_DATA_ROOT\"]=\"/notebooks/kaggle/csiro\"\n",
        "os.environ[\"DINO_B_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitb16_pretrain.pth\"\n",
        "os.environ[\"DINO_L_WEIGHTS_PATH\"] = \"/notebooks/kaggle/csiro/weights/dinov3/dinov3_vitl16_pretrain.pth\"\n",
        "\n",
        "from csiro.config import DEFAULTS, DEFAULT_DATA_ROOT, DINO_B_WEIGHTS_PATH, dino_hub_name\n",
        "from csiro.data import load_train_wide, BiomassTiledCached, TiledTransformView\n",
        "from csiro.eval import ttt_sweep_cv\n",
        "from csiro.transforms import post_tfms\n",
        "\n",
        "# --- paths / config ---\n",
        "TRAIN_CSV = \"/notebooks/kaggle/csiro/train.csv\"  # e.g. \"/notebooks/kaggle/csiro/train.csv\"\n",
        "DATA_ROOT = DEFAULT_DATA_ROOT\n",
        "DINO_REPO = \"/notebooks/dinov3\"\n",
        "DINO_WEIGHTS = DINO_B_WEIGHTS_PATH\n",
        "PT_PATHS = [\n",
        "     \"/notebooks/kaggle/csiro/output/v7_n_models2_f2c.pt\",\n",
        "]\n",
        "CV_PARAMS = dict(mode=\"gkf\", cv_seed=126015, n_splits=5)\n",
        "\n",
        "IMG_SIZE = int(DEFAULTS.get(\"img_size\", 512))\n",
        "CACHE_IMAGES = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d7f2de1",
      "metadata": {},
      "source": [
        "# TTT Sweep: Load Data & Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "96a1c2f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- data ---\n",
        "wide_df = load_train_wide(TRAIN_CSV, root=DATA_ROOT)\n",
        "base_ds = BiomassTiledCached(wide_df, img_size=IMG_SIZE, cache_images=CACHE_IMAGES)\n",
        "dataset = TiledTransformView(\n",
        "    base_ds,\n",
        "    post_tfms(),\n",
        "    tile_swap=False,\n",
        ")\n",
        "\n",
        "# --- backbone ---\n",
        "backbone = torch.hub.load(\n",
        "    DINO_REPO,\n",
        "    dino_hub_name(model_size=str(DEFAULTS.get(\"backbone_size\", \"b\")), plus=str(DEFAULTS.get(\"plus\", \"\"))),\n",
        "    source=\"local\",\n",
        "    weights=DINO_WEIGHTS,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85863f5a",
      "metadata": {},
      "source": [
        "# TTT Sweep: Define Tasks + Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a18bf39b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07dfacb9b8ee421389212c7456ec73c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTT sweeps:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e275b62e08b4b2093f6b8ca3f6efdc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "rdrop_head folds:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'name': 'rdrop_head',\n",
              "  'steps': 2,\n",
              "  'lr': 1e-05,\n",
              "  'beta': 0.001,\n",
              "  'batch_size': 1,\n",
              "  'inner_agg': 'mean',\n",
              "  'outer_agg': 'mean',\n",
              "  'fold_base': [0.7638000249862671,\n",
              "   0.791303277015686,\n",
              "   0.8119305372238159,\n",
              "   0.7919535636901855,\n",
              "   0.6741432547569275],\n",
              "  'fold_ttt': [0.7639871835708618,\n",
              "   0.7910223007202148,\n",
              "   0.8120127320289612,\n",
              "   0.7919400930404663,\n",
              "   0.6741708517074585],\n",
              "  'fold_delta': [0.00018715858459472656,\n",
              "   -0.0002809762954711914,\n",
              "   8.219480514526367e-05,\n",
              "   -1.3470649719238281e-05,\n",
              "   2.759695053100586e-05],\n",
              "  'fold_ssl_loss': [59.77405280549381,\n",
              "   73.71202138381105,\n",
              "   42.57313870523178,\n",
              "   38.42300206260837,\n",
              "   49.409532335742064],\n",
              "  'fold_reg_loss': [8.190341677258662e-13,\n",
              "   8.836147117730233e-13,\n",
              "   6.809401175891604e-13,\n",
              "   2.7796955003011997e-13,\n",
              "   8.106596677978638e-13],\n",
              "  'mean_base': 0.7666261315345764,\n",
              "  'mean_ttt': 0.7666266322135925,\n",
              "  'mean_delta': 5.006790161132813e-07,\n",
              "  'mean_ssl_loss': 52.778349458577416,\n",
              "  'mean_reg_loss': 6.944436429832068e-13}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torchvision.transforms.functional as TF\n",
        "from csiro.config import IMAGENET_MEAN, IMAGENET_STD\n",
        "\n",
        "class RDropPredMSE(torch.nn.Module):\n",
        "    # Example task: MSE between two dropout passes on final preds.\n",
        "    def __init__(self, name: str = \"rdrop_pred_mse\"):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, model, x, ctx):\n",
        "        if hasattr(model, \"set_train\"):\n",
        "            model.set_train(True)\n",
        "        model.train()\n",
        "        p1 = model(x)\n",
        "        p2 = model(x)\n",
        "        return ((p1.float() - p2.float()) ** 2).mean()\n",
        "\n",
        "\n",
        "class JitterRotPredMSE(torch.nn.Module):\n",
        "    # Color jitter + rot90 invariance on final preds.\n",
        "    def __init__(self, bcs_val: float = 0.2, hue_val: float = 0.02, rot_k: int = 1, name: str = \"jitter_rot_pred_mse\"):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.bcs_val = float(bcs_val)\n",
        "        self.hue_val = float(hue_val)\n",
        "        self.rot_k = int(rot_k)\n",
        "\n",
        "    def _apply_jitter_batch(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.bcs_val <= 0.0 and self.hue_val <= 0.0:\n",
        "            return x\n",
        "        if self.bcs_val > 0.0:\n",
        "            b = float(self.bcs_val)\n",
        "            brightness = float(1.0 + (torch.rand((), device=x.device) * 2.0 - 1.0) * b)\n",
        "            contrast = float(1.0 + (torch.rand((), device=x.device) * 2.0 - 1.0) * b)\n",
        "            saturation = float(1.0 + (torch.rand((), device=x.device) * 2.0 - 1.0) * b)\n",
        "            x = TF.adjust_brightness(x, brightness)\n",
        "            x = TF.adjust_contrast(x, contrast)\n",
        "            x = TF.adjust_saturation(x, saturation)\n",
        "        if self.hue_val > 0.0:\n",
        "            hue = float((torch.rand((), device=x.device) * 2.0 - 1.0) * self.hue_val)\n",
        "            x = TF.adjust_hue(x, hue)\n",
        "        return x\n",
        "\n",
        "    def forward(self, model, x, ctx):\n",
        "        if hasattr(model, \"set_train\"):\n",
        "            model.set_train(True)\n",
        "        model.train()\n",
        "        if x.ndim != 5 or x.size(1) != 2:\n",
        "            raise ValueError(f\"Expected tiled input [B,2,C,H,W], got {tuple(x.shape)}\")\n",
        "\n",
        "        x = x.float()\n",
        "        mean = torch.tensor(IMAGENET_MEAN, device=x.device).view(1, 1, 3, 1, 1)\n",
        "        std = torch.tensor(IMAGENET_STD, device=x.device).view(1, 1, 3, 1, 1)\n",
        "        x_unn = (x * std + mean).clamp(0.0, 1.0)\n",
        "\n",
        "        b, tiles, c, h, w = x_unn.shape\n",
        "        x_flat = x_unn.view(b * tiles, c, h, w)\n",
        "        x1 = self._apply_jitter_batch(x_flat)\n",
        "        x2 = self._apply_jitter_batch(x_flat)\n",
        "        x2 = torch.rot90(x2, k=self.rot_k, dims=(-2, -1))\n",
        "\n",
        "        mean_f = mean.view(1, 3, 1, 1)\n",
        "        std_f = std.view(1, 3, 1, 1)\n",
        "        x1 = (x1 - mean_f) / std_f\n",
        "        x2 = (x2 - mean_f) / std_f\n",
        "\n",
        "        x1 = x1.view(b, tiles, c, h, w)\n",
        "        x2 = x2.view(b, tiles, c, h, w)\n",
        "        p1 = model(x1)\n",
        "        p2 = model(x2)\n",
        "        p1 = torch.expm1(p1.float()).clamp_min(0.0)\n",
        "        p2 = torch.expm1(p2.float()).clamp_min(0.0)\n",
        "        return ((p1 - p2) ** 2).mean()\n",
        "\n",
        "\n",
        "TASKS = [\n",
        "    #RDropPredMSE(),\n",
        "    JitterRotPredMSE(bcs_val=0, hue_val=0),\n",
        "]\n",
        "\n",
        "# Param specs: strings can be module names (\"head\", \"neck\", \"norm\") or exact parameter names.\n",
        "PARAM_SPECS = [\n",
        "    [\"norm\"],\n",
        "]\n",
        "\n",
        "SWEEPS = [\n",
        "    dict(\n",
        "        name=\"rdrop_head\",\n",
        "        task=TASKS[0],\n",
        "        params=PARAM_SPECS[0],\n",
        "        steps=2,\n",
        "        lr=1e-5,\n",
        "        beta=1e-3,\n",
        "        batch_size=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "results = ttt_sweep_cv(\n",
        "    dataset=dataset,\n",
        "    wide_df=wide_df,\n",
        "    backbone=backbone,\n",
        "    pt_paths=PT_PATHS,\n",
        "    cv_params=CV_PARAMS,\n",
        "    sweeps=SWEEPS,\n",
        "    batch_size=32,\n",
        "    num_workers=DEFAULTS.get(\"num_workers\", 4),\n",
        "    device=DEFAULTS.get(\"device\", \"cuda\"),\n",
        "    inner_agg=\"mean\",\n",
        "    outer_agg=\"mean\",\n",
        ")\n",
        "\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c0d427da",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b7fe1c99e6a49c58e2dd072318b73cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTT sweeps:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8e9e0459622438f8ae3ae366758eb1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "rdrop_head folds:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'name': 'rdrop_head',\n",
              "  'steps': 3,\n",
              "  'lr': 1e-06,\n",
              "  'beta': 0.001,\n",
              "  'batch_size': 1,\n",
              "  'inner_agg': 'mean',\n",
              "  'outer_agg': 'mean',\n",
              "  'fold_base': [0.7638000249862671,\n",
              "   0.791303277015686,\n",
              "   0.8119305372238159,\n",
              "   0.7919535636901855,\n",
              "   0.6741432547569275],\n",
              "  'fold_ttt': [0.7722742557525635,\n",
              "   0.6596822142601013,\n",
              "   0.7087408304214478,\n",
              "   0.7614954113960266,\n",
              "   0.6227894425392151],\n",
              "  'fold_delta': [0.008474230766296387,\n",
              "   -0.13162106275558472,\n",
              "   -0.10318970680236816,\n",
              "   -0.030458152294158936,\n",
              "   -0.0513538122177124],\n",
              "  'fold_ssl_loss': [47.099459728813386,\n",
              "   65.36874894573934,\n",
              "   44.56800474338409,\n",
              "   34.06877033563628,\n",
              "   39.2964903256097],\n",
              "  'fold_reg_loss': [8.99256165935054e-12,\n",
              "   1.6505451528317844e-11,\n",
              "   8.102821511877658e-12,\n",
              "   3.3006679239712078e-12,\n",
              "   5.326725652207592e-12],\n",
              "  'mean_base': 0.7666261315345764,\n",
              "  'mean_ttt': 0.7049964308738709,\n",
              "  'mean_delta': -0.06162970066070557,\n",
              "  'mean_ssl_loss': 46.08029481583656,\n",
              "  'mean_reg_loss': 8.445645655144969e-12}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torchvision.transforms.functional as TF\n",
        "from csiro.config import IMAGENET_MEAN, IMAGENET_STD\n",
        "\n",
        "class RDropPredMSE(torch.nn.Module):\n",
        "    # Example task: MSE between two dropout passes on final preds.\n",
        "    def __init__(self, name: str = \"rdrop_pred_mse\"):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, model, x, ctx):\n",
        "        if hasattr(model, \"set_train\"):\n",
        "            model.set_train(True)\n",
        "        model.train()\n",
        "        p1 = model(x)\n",
        "        p2 = model(x)\n",
        "        return ((p1.float() - p2.float()) ** 2).mean()\n",
        "\n",
        "\n",
        "class JitterRotPredMSE(torch.nn.Module):\n",
        "    # Color jitter + rot90 invariance on final preds.\n",
        "    def __init__(self, bcs_val: float = 0.2, hue_val: float = 0.02, rot_k: int = 1, name: str = \"jitter_rot_pred_mse\"):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.bcs_val = float(bcs_val)\n",
        "        self.hue_val = float(hue_val)\n",
        "        self.rot_k = int(rot_k)\n",
        "\n",
        "    def _apply_jitter_batch(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.bcs_val <= 0.0 and self.hue_val <= 0.0:\n",
        "            return x\n",
        "        if self.bcs_val > 0.0:\n",
        "            b = float(self.bcs_val)\n",
        "            brightness = float(1.0 + (torch.rand((), device=x.device) * 2.0 - 1.0) * b)\n",
        "            contrast = float(1.0 + (torch.rand((), device=x.device) * 2.0 - 1.0) * b)\n",
        "            saturation = float(1.0 + (torch.rand((), device=x.device) * 2.0 - 1.0) * b)\n",
        "            x = TF.adjust_brightness(x, brightness)\n",
        "            x = TF.adjust_contrast(x, contrast)\n",
        "            x = TF.adjust_saturation(x, saturation)\n",
        "        if self.hue_val > 0.0:\n",
        "            hue = float((torch.rand((), device=x.device) * 2.0 - 1.0) * self.hue_val)\n",
        "            x = TF.adjust_hue(x, hue)\n",
        "        return x\n",
        "\n",
        "    def forward(self, model, x, ctx):\n",
        "        if hasattr(model, \"set_train\"):\n",
        "            model.set_train(True)\n",
        "        model.train()\n",
        "        if x.ndim != 5 or x.size(1) != 2:\n",
        "            raise ValueError(f\"Expected tiled input [B,2,C,H,W], got {tuple(x.shape)}\")\n",
        "\n",
        "        x = x.float()\n",
        "        mean = torch.tensor(IMAGENET_MEAN, device=x.device).view(1, 1, 3, 1, 1)\n",
        "        std = torch.tensor(IMAGENET_STD, device=x.device).view(1, 1, 3, 1, 1)\n",
        "        x_unn = (x * std + mean).clamp(0.0, 1.0)\n",
        "\n",
        "        b, tiles, c, h, w = x_unn.shape\n",
        "        x_flat = x_unn.view(b * tiles, c, h, w)\n",
        "        x1 = self._apply_jitter_batch(x_flat)\n",
        "        x2 = self._apply_jitter_batch(x_flat)\n",
        "        x2 = torch.rot90(x2, k=self.rot_k, dims=(-2, -1))\n",
        "\n",
        "        mean_f = mean.view(1, 3, 1, 1)\n",
        "        std_f = std.view(1, 3, 1, 1)\n",
        "        x1 = (x1 - mean_f) / std_f\n",
        "        x2 = (x2 - mean_f) / std_f\n",
        "\n",
        "        x1 = x1.view(b, tiles, c, h, w)\n",
        "        x2 = x2.view(b, tiles, c, h, w)\n",
        "        p1 = model(x1)\n",
        "        p2 = model(x2)\n",
        "        p1 = torch.expm1(p1.float()).clamp_min(0.0)\n",
        "        p2 = torch.expm1(p2.float()).clamp_min(0.0)\n",
        "        return ((p1 - p2) ** 2).mean()\n",
        "\n",
        "\n",
        "TASKS = [\n",
        "    #RDropPredMSE(),\n",
        "    JitterRotPredMSE(bcs_val=0, hue_val=0),\n",
        "]\n",
        "\n",
        "# Param specs: strings can be module names (\"head\", \"neck\", \"norm\") or exact parameter names.\n",
        "PARAM_SPECS = [\n",
        "    [\"head\"],\n",
        "]\n",
        "\n",
        "SWEEPS = [\n",
        "    dict(\n",
        "        name=\"rdrop_head\",\n",
        "        task=TASKS[0],\n",
        "        params=PARAM_SPECS[0],\n",
        "        steps=3,\n",
        "        lr=1e-6,\n",
        "        beta=1e-3,\n",
        "        batch_size=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "results = ttt_sweep_cv(\n",
        "    dataset=dataset,\n",
        "    wide_df=wide_df,\n",
        "    backbone=backbone,\n",
        "    pt_paths=PT_PATHS,\n",
        "    cv_params=CV_PARAMS,\n",
        "    sweeps=SWEEPS,\n",
        "    batch_size=32,\n",
        "    num_workers=DEFAULTS.get(\"num_workers\", 4),\n",
        "    device=DEFAULTS.get(\"device\", \"cuda\"),\n",
        "    inner_agg=\"mean\",\n",
        "    outer_agg=\"mean\",\n",
        ")\n",
        "\n",
        "results\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}