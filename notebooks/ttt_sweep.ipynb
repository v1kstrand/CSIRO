{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2ae06b90",
      "metadata": {},
      "source": [
        "# TTT Sweep: Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e40d79",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from csiro.config import DEFAULTS, DEFAULT_DATA_ROOT, DEFAULT_DINO_REPO_DIR, DINO_WEIGHTS_PATH, dino_hub_name\n",
        "from csiro.data import load_train_wide, BiomassTiledCached, TiledTTADataset\n",
        "from csiro.eval import ttt_sweep_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d7f2de1",
      "metadata": {},
      "source": [
        "# TTT Sweep: Load Data & Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb157ac0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- paths / config ---\n",
        "TRAIN_CSV = None  # e.g. \"/notebooks/kaggle/csiro/train.csv\"\n",
        "DATA_ROOT = DEFAULT_DATA_ROOT\n",
        "DINO_REPO = DEFAULT_DINO_REPO_DIR\n",
        "DINO_WEIGHTS = DINO_WEIGHTS_PATH\n",
        "PT_PATHS = [\n",
        "    # \"/notebooks/kaggle/csiro/output/run.pt\",\n",
        "]\n",
        "CV_PARAMS = dict(mode=\"gkf\", cv_seed=0, n_splits=5)\n",
        "\n",
        "IMG_SIZE = int(DEFAULTS.get(\"img_size\", 512))\n",
        "CACHE_IMAGES = True\n",
        "\n",
        "# TTA for sweep (should match your validation/inference pipeline)\n",
        "TTA_N = 4\n",
        "TTA_BCS = 0.0\n",
        "TTA_HUE = 0.0\n",
        "\n",
        "# --- data ---\n",
        "wide_df = load_train_wide(TRAIN_CSV, root=DATA_ROOT)\n",
        "base_ds = BiomassTiledCached(wide_df, img_size=IMG_SIZE, cache_images=CACHE_IMAGES)\n",
        "dataset = TiledTTADataset(\n",
        "    base_ds,\n",
        "    tta_n=int(TTA_N),\n",
        "    bcs_val=float(TTA_BCS),\n",
        "    hue_val=float(TTA_HUE),\n",
        "    apply_post_tfms=True,\n",
        ")\n",
        "\n",
        "# --- backbone ---\n",
        "backbone = torch.hub.load(\n",
        "    DINO_REPO,\n",
        "    dino_hub_name(model_size=str(DEFAULTS.get(\"backbone_size\", \"b\")), plus=str(DEFAULTS.get(\"plus\", \"\"))),\n",
        "    source=\"local\",\n",
        "    weights=DINO_WEIGHTS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85863f5a",
      "metadata": {},
      "source": [
        "# TTT Sweep: Define Tasks + Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d427da",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RDropPredMSE(torch.nn.Module):\n",
        "    # Example task: MSE between two dropout passes on final preds.\n",
        "    def __init__(self, name: str = \"rdrop_pred_mse\"):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, model, x, ctx):\n",
        "        if hasattr(model, \"set_train\"):\n",
        "            model.set_train(True)\n",
        "        model.train()\n",
        "        p1 = model(x)\n",
        "        p2 = model(x)\n",
        "        return ((p1.float() - p2.float()) ** 2).mean()\n",
        "\n",
        "\n",
        "TASKS = [\n",
        "    RDropPredMSE(),\n",
        "]\n",
        "\n",
        "# Param specs: strings can be module names (\"head\", \"neck\", \"norm\") or exact parameter names.\n",
        "PARAM_SPECS = [\n",
        "    [\"head\"],\n",
        "]\n",
        "\n",
        "SWEEPS = [\n",
        "    dict(\n",
        "        name=\"rdrop_head\",\n",
        "        task=TASKS[0],\n",
        "        params=PARAM_SPECS[0],\n",
        "        steps=1,\n",
        "        lr=1e-5,\n",
        "        beta=0.0,\n",
        "        batch_size=16,\n",
        "    ),\n",
        "]\n",
        "\n",
        "results = ttt_sweep_cv(\n",
        "    dataset=dataset,\n",
        "    wide_df=wide_df,\n",
        "    backbone=backbone,\n",
        "    pt_paths=PT_PATHS,\n",
        "    cv_params=CV_PARAMS,\n",
        "    sweeps=SWEEPS,\n",
        "    batch_size=32,\n",
        "    num_workers=DEFAULTS.get(\"num_workers\", 4),\n",
        "    device=DEFAULTS.get(\"device\", \"cuda\"),\n",
        "    inner_agg=\"mean\",\n",
        "    outer_agg=\"mean\",\n",
        ")\n",
        "\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch 2.7.1 (cu118)",
      "language": "python",
      "name": "pt27cu118"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
